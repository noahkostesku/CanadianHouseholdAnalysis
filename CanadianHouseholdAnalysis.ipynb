{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Dataset</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We will start by importing all requied libraries needed for this project.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import re\n",
    "\n",
    "# Dimensionality Reduction\n",
    "from scipy.sparse import csr_matrix\n",
    "import sklearn.feature_extraction.text as sktext\n",
    "from sklearn.decomposition import PCA, SparsePCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "import umap.plot\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans, SpectralClustering\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "from yellowbrick.cluster.elbow import kelbow_visualizer\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculations\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load Data</h3>\n",
    "<p>Loading in both of our datasets from local files.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_stats_df = pl.read_csv(\"Coursework Data/DemoStats.csv\", null_values=None)\n",
    "household_spend_df = pl.read_csv(\"Coursework Data/HouseholdSpend.csv\", null_values=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Merging Data</h3>\n",
    "<p>Next, we will combine these two datasets into one. We joined them on the \"CODE\" column, which is the common column between the two datasets.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 980)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>ECYASQKM</th><th>ECYALSQKM</th><th>ECYBASPOP</th><th>ECYBASHHD</th><th>ECYBASHPOP</th><th>ECYBAS12P</th><th>ECYBAS15P</th><th>ECYBAS18P</th><th>ECYBAS19P</th><th>ECYBAS12HP</th><th>ECYBAS15HP</th><th>ECYBAS18HP</th><th>ECYBAS19HP</th><th>ECYBASTNGH</th><th>ECYBASADUH</th><th>ECYBASCF</th><th>ECYBASCFH</th><th>ECYBASKID</th><th>ECYBASLF</th><th>ECYPTAPOP</th><th>ECYPTA_0_4</th><th>ECYPTA_5_9</th><th>ECYPTA1014</th><th>ECYPTA1519</th><th>ECYPTA2024</th><th>ECYPTA2529</th><th>ECYPTA3034</th><th>ECYPTA3539</th><th>ECYPTA4044</th><th>ECYPTA4549</th><th>ECYPTA5054</th><th>ECYPTA5559</th><th>ECYPTA6064</th><th>ECYPTA6569</th><th>ECYPTA7074</th><th>ECYPTA7579</th><th>&hellip;</th><th>HSTR002</th><th>HSTR003</th><th>HSTR004</th><th>HSTR005</th><th>HSTR006</th><th>HSTR007</th><th>HSTR008</th><th>HSTR009</th><th>HSTR058</th><th>HSTR010</th><th>HSTR011</th><th>HSTR012</th><th>HSTR014M</th><th>HSTR015</th><th>HSTR020</th><th>HSTR030</th><th>HSTR031</th><th>HSTR032</th><th>HSTR033</th><th>HSTR034</th><th>HSTR035</th><th>HSTR036</th><th>HSTR037</th><th>HSTR038</th><th>HSTR039</th><th>HSTR040</th><th>HSTR041</th><th>HSTR050</th><th>HSTR051</th><th>HSTR052</th><th>HSTR053</th><th>HSTR054</th><th>HSTR055</th><th>HSTR056</th><th>HSTR056A</th><th>HSTR056B</th><th>HSTR057</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>&hellip;</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td><td>868970.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>0.0</td><td>0.0</td><td>46.684199</td><td>18.432629</td><td>45.881762</td><td>41.254934</td><td>39.613594</td><td>37.819792</td><td>37.323999</td><td>40.336732</td><td>38.832472</td><td>37.263988</td><td>36.746572</td><td>3.072744</td><td>24.49923</td><td>12.76093</td><td>12.051364</td><td>12.740845</td><td>24.633679</td><td>46.684199</td><td>2.181318</td><td>2.390635</td><td>2.498651</td><td>2.672259</td><td>3.213171</td><td>3.308621</td><td>3.406466</td><td>3.258362</td><td>3.117668</td><td>2.858167</td><td>2.776588</td><td>2.859335</td><td>3.10898</td><td>2.80384</td><td>2.278714</td><td>1.770631</td><td>&hellip;</td><td>236398.761036</td><td>118477.006209</td><td>114562.677761</td><td>14888.288571</td><td>8607.895903</td><td>91066.493288</td><td>188.957063</td><td>83.539013</td><td>105.41805</td><td>3725.371385</td><td>3469.552047</td><td>2092.59778</td><td>1376.954267</td><td>255.819338</td><td>1504.664209</td><td>116417.090618</td><td>3287.664753</td><td>10103.061471</td><td>12676.188385</td><td>18214.142317</td><td>100.530695</td><td>63415.559732</td><td>2639.560863</td><td>4612.181943</td><td>1368.200459</td><td>379.01064</td><td>989.189819</td><td>34736.610626</td><td>5995.306708</td><td>2258.469958</td><td>915.416319</td><td>23038.220756</td><td>71.1409</td><td>1322.434304</td><td>831.592595</td><td>490.84171</td><td>1135.621681</td></tr><tr><td>&quot;std&quot;</td><td>0.0</td><td>0.0</td><td>174.837877</td><td>69.379951</td><td>171.817976</td><td>152.539099</td><td>145.876662</td><td>139.320601</td><td>137.611402</td><td>149.038058</td><td>143.038376</td><td>137.181937</td><td>135.319262</td><td>12.468123</td><td>87.647782</td><td>50.126862</td><td>47.828225</td><td>49.02113</td><td>89.352097</td><td>174.837877</td><td>9.518254</td><td>10.400337</td><td>10.705186</td><td>10.30089</td><td>10.888878</td><td>10.894537</td><td>11.699239</td><td>11.371185</td><td>11.099312</td><td>10.485757</td><td>10.544898</td><td>11.657788</td><td>13.69638</td><td>12.729886</td><td>10.420684</td><td>8.140557</td><td>&hellip;</td><td>990960.632583</td><td>507452.95803</td><td>494184.487741</td><td>58848.760548</td><td>45895.371562</td><td>398856.15598</td><td>794.022208</td><td>358.55285</td><td>497.256289</td><td>14112.764792</td><td>13213.369738</td><td>8173.498909</td><td>5705.767025</td><td>1422.161917</td><td>5673.303299</td><td>486744.921092</td><td>14400.182837</td><td>39378.141535</td><td>60281.31644</td><td>71889.568827</td><td>615.785308</td><td>284702.777168</td><td>13567.714202</td><td>14917.235034</td><td>5725.037991</td><td>2091.296014</td><td>3882.026395</td><td>101629.434794</td><td>19414.670337</td><td>7613.821326</td><td>5037.673958</td><td>71509.135272</td><td>257.018871</td><td>6638.799848</td><td>5076.885882</td><td>2097.649493</td><td>4203.801021</td></tr><tr><td>&quot;min&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>0.0</td><td>0.0</td><td>8.0</td><td>3.0</td><td>7.0</td><td>7.0</td><td>7.0</td><td>6.0</td><td>6.0</td><td>7.0</td><td>7.0</td><td>6.0</td><td>6.0</td><td>0.0</td><td>4.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>4.0</td><td>8.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>31974.915025</td><td>14884.392499</td><td>14404.559008</td><td>1721.930707</td><td>889.08304</td><td>10994.748987</td><td>18.79587</td><td>8.307298</td><td>6.952265</td><td>341.867661</td><td>307.276114</td><td>167.899519</td><td>93.667955</td><td>6.870296</td><td>105.847834</td><td>16361.845444</td><td>313.292801</td><td>1178.97798</td><td>1513.451358</td><td>2469.125994</td><td>7.898357</td><td>8700.00923</td><td>189.507627</td><td>384.138866</td><td>151.543329</td><td>37.742767</td><td>93.143563</td><td>2811.475222</td><td>162.774495</td><td>167.312143</td><td>35.976385</td><td>1768.315493</td><td>6.114269</td><td>85.412388</td><td>36.712766</td><td>23.624462</td><td>88.826063</td></tr><tr><td>&quot;50%&quot;</td><td>0.0</td><td>0.0</td><td>21.0</td><td>8.0</td><td>21.0</td><td>19.0</td><td>19.0</td><td>18.0</td><td>17.0</td><td>19.0</td><td>18.0</td><td>17.0</td><td>17.0</td><td>1.0</td><td>11.0</td><td>6.0</td><td>5.0</td><td>5.0</td><td>11.0</td><td>21.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>2.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>&hellip;</td><td>99636.881325</td><td>47255.263545</td><td>45702.223467</td><td>5675.289883</td><td>3012.454702</td><td>35561.278678</td><td>64.954671</td><td>29.399074</td><td>27.016134</td><td>1221.710075</td><td>1114.524975</td><td>634.507481</td><td>383.183443</td><td>48.33781</td><td>455.550063</td><td>50448.828495</td><td>1010.89752</td><td>4106.746145</td><td>4918.767677</td><td>7819.010503</td><td>30.350255</td><td>26710.649778</td><td>726.944444</td><td>1601.499714</td><td>495.907153</td><td>121.108084</td><td>342.930165</td><td>10954.693342</td><td>1156.778626</td><td>701.484161</td><td>161.412101</td><td>7057.834978</td><td>23.787995</td><td>343.285857</td><td>161.941917</td><td>117.546716</td><td>354.380653</td></tr><tr><td>&quot;75%&quot;</td><td>0.0</td><td>0.0</td><td>47.0</td><td>18.0</td><td>46.0</td><td>41.0</td><td>40.0</td><td>38.0</td><td>38.0</td><td>41.0</td><td>39.0</td><td>38.0</td><td>37.0</td><td>3.0</td><td>25.0</td><td>13.0</td><td>12.0</td><td>12.0</td><td>25.0</td><td>47.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>2.0</td><td>2.0</td><td>&hellip;</td><td>234841.660337</td><td>116289.221612</td><td>112200.441102</td><td>15018.869906</td><td>8150.993847</td><td>87545.046991</td><td>180.270628</td><td>78.649214</td><td>86.006103</td><td>3560.668285</td><td>3296.700024</td><td>1929.993628</td><td>1207.25064</td><td>209.470357</td><td>1429.641014</td><td>116348.736875</td><td>2834.456579</td><td>10240.10095</td><td>12318.235716</td><td>18680.935475</td><td>86.966083</td><td>61627.089698</td><td>2153.664949</td><td>4785.370267</td><td>1321.914033</td><td>341.421503</td><td>954.217924</td><td>34053.319991</td><td>4960.248059</td><td>2008.694424</td><td>540.584951</td><td>22586.713725</td><td>63.703739</td><td>1023.247916</td><td>544.115663</td><td>420.149131</td><td>1009.684299</td></tr><tr><td>&quot;max&quot;</td><td>0.0</td><td>0.0</td><td>23507.0</td><td>7751.0</td><td>23378.0</td><td>20141.0</td><td>19020.0</td><td>17849.0</td><td>17487.0</td><td>19950.0</td><td>18891.0</td><td>17781.0</td><td>17436.0</td><td>2169.0</td><td>11623.0</td><td>6837.0</td><td>6487.0</td><td>8218.0</td><td>13551.0</td><td>23507.0</td><td>1241.0</td><td>1530.0</td><td>1791.0</td><td>1871.0</td><td>1954.0</td><td>1200.0</td><td>1478.0</td><td>1437.0</td><td>1811.0</td><td>1723.0</td><td>1617.0</td><td>1545.0</td><td>1393.0</td><td>1293.0</td><td>1193.0</td><td>1139.0</td><td>&hellip;</td><td>1.2796e8</td><td>7.0898e7</td><td>6.8704e7</td><td>8.7079e6</td><td>1.0164e7</td><td>5.2694e7</td><td>98537.879231</td><td>43886.395799</td><td>62217.543041</td><td>2.1477e6</td><td>2.1443e6</td><td>1.3459e6</td><td>895523.577009</td><td>272687.971232</td><td>1.1006e6</td><td>5.8696e7</td><td>1.9230e6</td><td>5.4522e6</td><td>9.1193e6</td><td>8.5339e6</td><td>128411.834084</td><td>3.7197e7</td><td>2.9165e6</td><td>1.8141e6</td><td>1.0225e6</td><td>406708.260287</td><td>615838.990473</td><td>1.2478e7</td><td>2.3201e6</td><td>1.0707e6</td><td>653408.354038</td><td>9.9506e6</td><td>29234.466882</td><td>1.4912e6</td><td>1.2078e6</td><td>397905.142758</td><td>733300.179849</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 980)\n",
       "┌───────────┬──────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ statistic ┆ ECYASQKM ┆ ECYALSQKM ┆ ECYBASPOP ┆ … ┆ HSTR056   ┆ HSTR056A  ┆ HSTR056B  ┆ HSTR057   │\n",
       "│ ---       ┆ ---      ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ str       ┆ f64      ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞═══════════╪══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ count     ┆ 868970.0 ┆ 868970.0  ┆ 868970.0  ┆ … ┆ 868970.0  ┆ 868970.0  ┆ 868970.0  ┆ 868970.0  │\n",
       "│ null_coun ┆ 0.0      ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ t         ┆          ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ mean      ┆ 0.0      ┆ 0.0       ┆ 46.684199 ┆ … ┆ 1322.4343 ┆ 831.59259 ┆ 490.84171 ┆ 1135.6216 │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 04        ┆ 5         ┆           ┆ 81        │\n",
       "│ std       ┆ 0.0      ┆ 0.0       ┆ 174.83787 ┆ … ┆ 6638.7998 ┆ 5076.8858 ┆ 2097.6494 ┆ 4203.8010 │\n",
       "│           ┆          ┆           ┆ 7         ┆   ┆ 48        ┆ 82        ┆ 93        ┆ 21        │\n",
       "│ min       ┆ 0.0      ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ 25%       ┆ 0.0      ┆ 0.0       ┆ 8.0       ┆ … ┆ 85.412388 ┆ 36.712766 ┆ 23.624462 ┆ 88.826063 │\n",
       "│ 50%       ┆ 0.0      ┆ 0.0       ┆ 21.0      ┆ … ┆ 343.28585 ┆ 161.94191 ┆ 117.54671 ┆ 354.38065 │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 7         ┆ 7         ┆ 6         ┆ 3         │\n",
       "│ 75%       ┆ 0.0      ┆ 0.0       ┆ 47.0      ┆ … ┆ 1023.2479 ┆ 544.11566 ┆ 420.14913 ┆ 1009.6842 │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 16        ┆ 3         ┆ 1         ┆ 99        │\n",
       "│ max       ┆ 0.0      ┆ 0.0       ┆ 23507.0   ┆ … ┆ 1.4912e6  ┆ 1.2078e6  ┆ 397905.14 ┆ 733300.17 │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆           ┆ 2758      ┆ 9849      │\n",
       "└───────────┴──────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = demo_stats_df.join(\n",
    "    household_spend_df,\n",
    "    on=[\"CODE\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Drop ID columns\n",
    "merged_df = merged_df.drop([\"GEO\", \"CODE\"])\n",
    "\n",
    "# Describe the data\n",
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The data is now merged. One thing that stands out to me is the extreme values at each end of the distribution. We will need to take a look at these values and see if they are valid or if they are outliers. We will do this later.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Part 1: Clustering and Dimensionality Reduction</h1>\n",
    "\n",
    "The first part of the coursework will focus\n",
    "on identifying the characteristics of Canadian households, excluding their pension\n",
    "behaviour. For this, do not include, in your clustering and dimensionality reduction models,\n",
    "the target of the regression model in Part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop target variable\n",
    "merged_df_clust = merged_df.drop(\"HSEP001S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Null Values</h3>\n",
    "<p>We will check for any null values in our dataset. If there are any, we will need to decide on how to handle them.</p>\n",
    "<p>From doing a quick scan of the database, it seems null values are listed as string of \"NA\"s. We will need to convert these to actual null values.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 868970\n",
      "Data Null Count: {'ECYPTAMED': {'null_count': 87459, 'less than 1%': True}, 'ECYPMAMED': {'null_count': 96444, 'less than 1%': True}, 'ECYPFAMED': {'null_count': 131837, 'less than 1%': True}, 'ECYHTAMED': {'null_count': 92709, 'less than 1%': True}, 'ECYHMAMED': {'null_count': 101698, 'less than 1%': True}, 'ECYHFAMED': {'null_count': 137900, 'less than 1%': True}, 'ECYMTNMED': {'null_count': 92709, 'less than 1%': True}}\n"
     ]
    }
   ],
   "source": [
    "total_data_points = merged_df_clust.height\n",
    "print(f\"Total data points: {total_data_points}\")\n",
    "# Define a function to convert NA to None\n",
    "def convert_na_to_nulls(df):\n",
    "    return df.with_columns([\n",
    "        pl.col(col).replace(\"NA\", None).alias(col)\n",
    "        if df.schema[col] == pl.Utf8 else pl.col(col)\n",
    "        for col in df.columns\n",
    "    ])\n",
    "\n",
    "# Convert NA to None on both dataframes\n",
    "merged_df_clust = convert_na_to_nulls(merged_df_clust)\n",
    "\n",
    "# Get total nulls for each column\n",
    "def count_na_strings(df):\n",
    "    total_rows = df.height\n",
    "    return {\n",
    "        col: {\n",
    "            \"null_count\": df[col].null_count(),\n",
    "            \"less than 1%\": 1 / total_rows < 0.01,\n",
    "        }\n",
    "        for col in df.columns\n",
    "        if df[col].null_count() > 0\n",
    "    }\n",
    "\n",
    "merged_df_nulls = count_na_strings(merged_df_clust)\n",
    "print(f\"Data Null Count: {merged_df_nulls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to turn any string into a number\n",
    "def convert_strings_to_numbers(df):\n",
    "    if hasattr(df, \"to_pandas\"):\n",
    "        df = df.to_pandas()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col in [\"CODE\", \"GEO\"]:\n",
    "            continue  # skip explicitly excluded columns\n",
    "\n",
    "        if df[col].dtype == \"object\" or pd.api.types.is_string_dtype(df[col]):\n",
    "            if (df[col] == \"NA\").any():\n",
    "                continue  # skip if \"NA\" appears in the column\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col])\n",
    "            except ValueError:\n",
    "                df[col] = df[col].astype(\"category\").cat.codes\n",
    "\n",
    "    return pl.from_pandas(df)\n",
    "\n",
    "# Convert df\n",
    "merged_df_clust = convert_strings_to_numbers(merged_df_clust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Wow, we have a lot of null values in our dataset. However, after a quick inspection, it seems a lot of these null values are soley from rows that contain only zero. Here is an example...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECYASQKM       0.0\n",
      "ECYALSQKM      0.0\n",
      "ECYBASPOP      0.0\n",
      "ECYBASHHD      0.0\n",
      "ECYBASHPOP     0.0\n",
      "ECYBAS12P      0.0\n",
      "ECYBAS15P      0.0\n",
      "ECYBAS18P      0.0\n",
      "ECYBAS19P      0.0\n",
      "ECYBAS12HP     0.0\n",
      "ECYBAS15HP     0.0\n",
      "ECYBAS18HP     0.0\n",
      "ECYBAS19HP     0.0\n",
      "ECYBASTNGH     0.0\n",
      "ECYBASADUH     0.0\n",
      "ECYBASCF       0.0\n",
      "ECYBASCFH      0.0\n",
      "ECYBASKID      0.0\n",
      "ECYBASLF       0.0\n",
      "ECYPTAPOP      0.0\n",
      "ECYPTA_0_4     0.0\n",
      "ECYPTA_5_9     0.0\n",
      "ECYPTA1014     0.0\n",
      "ECYPTA1519     0.0\n",
      "ECYPTA2024     0.0\n",
      "ECYPTA2529     0.0\n",
      "ECYPTA3034     0.0\n",
      "ECYPTA3539     0.0\n",
      "ECYPTA4044     0.0\n",
      "ECYPTA4549     0.0\n",
      "ECYPTA5054     0.0\n",
      "ECYPTA5559     0.0\n",
      "ECYPTA6064     0.0\n",
      "ECYPTA6569     0.0\n",
      "ECYPTA7074     0.0\n",
      "ECYPTA7579     0.0\n",
      "ECYPTA8084     0.0\n",
      "ECYPTA85P      0.0\n",
      "ECYPTAAVG      0.0\n",
      "ECYPTAMED      NaN\n",
      "ECYPMAPOP      0.0\n",
      "ECYPMA_0_4     0.0\n",
      "ECYPMA_5_9     0.0\n",
      "ECYPMA1014     0.0\n",
      "ECYPMA1519     0.0\n",
      "ECYPMA2024     0.0\n",
      "ECYPMA2529     0.0\n",
      "ECYPMA3034     0.0\n",
      "ECYPMA3539     0.0\n",
      "ECYPMA4044     0.0\n",
      "ECYPMA4549     0.0\n",
      "ECYPMA5054     0.0\n",
      "ECYPMA5559     0.0\n",
      "ECYPMA6064     0.0\n",
      "ECYPMA6569     0.0\n",
      "ECYPMA7074     0.0\n",
      "ECYPMA7579     0.0\n",
      "ECYPMA8084     0.0\n",
      "ECYPMA85P      0.0\n",
      "ECYPMAAVG      0.0\n",
      "ECYPMAMED      NaN\n",
      "ECYPFAPOP      0.0\n",
      "ECYPFA_0_4     0.0\n",
      "ECYPFA_5_9     0.0\n",
      "ECYPFA1014     0.0\n",
      "ECYPFA1519     0.0\n",
      "ECYPFA2024     0.0\n",
      "ECYPFA2529     0.0\n",
      "ECYPFA3034     0.0\n",
      "ECYPFA3539     0.0\n",
      "ECYPFA4044     0.0\n",
      "ECYPFA4549     0.0\n",
      "ECYPFA5054     0.0\n",
      "ECYPFA5559     0.0\n",
      "ECYPFA6064     0.0\n",
      "ECYPFA6569     0.0\n",
      "ECYPFA7074     0.0\n",
      "ECYPFA7579     0.0\n",
      "ECYPFA8084     0.0\n",
      "ECYPFA85P      0.0\n",
      "ECYPFAAVG      0.0\n",
      "ECYPFAMED      NaN\n",
      "ECYHTAHPOP     0.0\n",
      "ECYHTA_0_4     0.0\n",
      "ECYHTA_5_9     0.0\n",
      "ECYHTA1014     0.0\n",
      "ECYHTA1519     0.0\n",
      "ECYHTA2024     0.0\n",
      "ECYHTA2529     0.0\n",
      "ECYHTA3034     0.0\n",
      "ECYHTA3539     0.0\n",
      "ECYHTA4044     0.0\n",
      "ECYHTA4549     0.0\n",
      "ECYHTA5054     0.0\n",
      "ECYHTA5559     0.0\n",
      "ECYHTA6064     0.0\n",
      "ECYHTA6569     0.0\n",
      "ECYHTA7074     0.0\n",
      "ECYHTA7579     0.0\n",
      "ECYHTA8084     0.0\n",
      "ECYHTA85P      0.0\n",
      "ECYHTAAVG      0.0\n",
      "ECYHTAMED      NaN\n",
      "ECYHMAHPOP     0.0\n",
      "ECYHMA_0_4     0.0\n",
      "ECYHMA_5_9     0.0\n",
      "ECYHMA1014     0.0\n",
      "ECYHMA1519     0.0\n",
      "ECYHMA2024     0.0\n",
      "ECYHMA2529     0.0\n",
      "ECYHMA3034     0.0\n",
      "ECYHMA3539     0.0\n",
      "ECYHMA4044     0.0\n",
      "ECYHMA4549     0.0\n",
      "ECYHMA5054     0.0\n",
      "ECYHMA5559     0.0\n",
      "ECYHMA6064     0.0\n",
      "ECYHMA6569     0.0\n",
      "ECYHMA7074     0.0\n",
      "ECYHMA7579     0.0\n",
      "ECYHMA8084     0.0\n",
      "ECYHMA85P      0.0\n",
      "ECYHMAAVG      0.0\n",
      "ECYHMAMED      NaN\n",
      "ECYHFAHPOP     0.0\n",
      "ECYHFA_0_4     0.0\n",
      "ECYHFA_5_9     0.0\n",
      "ECYHFA1014     0.0\n",
      "ECYHFA1519     0.0\n",
      "ECYHFA2024     0.0\n",
      "ECYHFA2529     0.0\n",
      "ECYHFA3034     0.0\n",
      "ECYHFA3539     0.0\n",
      "ECYHFA4044     0.0\n",
      "ECYHFA4549     0.0\n",
      "ECYHFA5054     0.0\n",
      "ECYHFA5559     0.0\n",
      "ECYHFA6064     0.0\n",
      "ECYHFA6569     0.0\n",
      "ECYHFA7074     0.0\n",
      "ECYHFA7579     0.0\n",
      "ECYHFA8084     0.0\n",
      "ECYHFA85P      0.0\n",
      "ECYHFAAVG      0.0\n",
      "ECYHFAMED      NaN\n",
      "ECYMTNHHD      0.0\n",
      "ECYMTN1524     0.0\n",
      "ECYMTN2534     0.0\n",
      "ECYMTN3544     0.0\n",
      "ECYMTN4554     0.0\n",
      "ECYMTN5564     0.0\n",
      "ECYMTN6574     0.0\n",
      "ECYMTN7584     0.0\n",
      "ECYMTN85P      0.0\n",
      "ECYMTNAVG      0.0\n",
      "ECYMTNMED      NaN\n",
      "ECYHSZHHD      0.0\n",
      "ECYHSZ1PER     0.0\n",
      "ECYHSZ2PER     0.0\n",
      "ECYHSZ3PER     0.0\n",
      "ECYHSZ4PER     0.0\n",
      "ECYHSZ5PER     0.0\n",
      "ECYHSZTPER     0.0\n",
      "ECYHSZAVG      0.0\n",
      "ECYHTYHHD      0.0\n",
      "ECYHTYFHT      0.0\n",
      "ECYHTY1FH      0.0\n",
      "ECYHTY1FHP     0.0\n",
      "ECYHTY1FHNP    0.0\n",
      "ECYHTYMGFH     0.0\n",
      "ECYHTYMFH      0.0\n",
      "ECYHTYNFH      0.0\n",
      "ECYHTY1PH      0.0\n",
      "ECYHTYN65A     0.0\n",
      "ECYHTY2PPH     0.0\n",
      "ECYMARHP15     0.0\n",
      "ECYMARMCL      0.0\n",
      "ECYMARM        0.0\n",
      "ECYMARCL       0.0\n",
      "ECYMARNMCL     0.0\n",
      "ECYMARSING     0.0\n",
      "ECYMARSEP      0.0\n",
      "ECYMARDIV      0.0\n",
      "ECYMARWID      0.0\n",
      "ECYCFSCF       0.0\n",
      "ECYCFSC        0.0\n",
      "ECYCFSCNC      0.0\n",
      "ECYCFSCWC      0.0\n",
      "ECYCFSM        0.0\n",
      "ECYCFSMNC      0.0\n",
      "ECYCFSMWC      0.0\n",
      "ECYCFSCL       0.0\n",
      "ECYCFSCLNC     0.0\n",
      "ECYCFSCLWC     0.0\n",
      "ECYCFSLP       0.0\n",
      "ECYCFSFP       0.0\n",
      "ECYCFSMP       0.0\n",
      "ECYCFSNFP      0.0\n",
      "ECYHFSCF       0.0\n",
      "ECYHFSC        0.0\n",
      "ECYHFSCNC      0.0\n",
      "ECYHFSCWC      0.0\n",
      "ECYHFSM        0.0\n",
      "ECYHFSMNC      0.0\n",
      "ECYHFSMWC      0.0\n",
      "ECYHFSCL       0.0\n",
      "ECYHFSCLNC     0.0\n",
      "ECYHFSCLWC     0.0\n",
      "ECYHFSLP       0.0\n",
      "ECYHFSFP       0.0\n",
      "ECYHFSMP       0.0\n",
      "ECYHFSWC       0.0\n",
      "ECYCHAKIDS     0.0\n",
      "ECYCHA_0_4     0.0\n",
      "ECYCHA_5_9     0.0\n",
      "ECYCHA1014     0.0\n",
      "ECYCHA1519     0.0\n",
      "ECYCHA2024     0.0\n",
      "ECYCHA25P      0.0\n",
      "ECYCHACFCH     0.0\n",
      "ECYCHAFHCH     0.0\n",
      "ECYCHAHHCH     0.0\n",
      "ECYMOBHPOP     0.0\n",
      "ECYMOBNMOV     0.0\n",
      "ECYMOBMOV      0.0\n",
      "ECYTENHHD      0.0\n",
      "ECYTENOWN      0.0\n",
      "ECYTENRENT     0.0\n",
      "ECYTENBAND     0.0\n",
      "ECYPOCHHD      0.0\n",
      "ECYPOCP60      0.0\n",
      "ECYPOC6180     0.0\n",
      "ECYPOC8190     0.0\n",
      "ECYPOC9100     0.0\n",
      "ECYPOC0105     0.0\n",
      "ECYPOC0610     0.0\n",
      "ECYPOC1115     0.0\n",
      "ECYPOC1621     0.0\n",
      "ECYPOC22P      0.0\n",
      "ECYSTYHHD      0.0\n",
      "ECYSTYHOUS     0.0\n",
      "ECYSTYSING     0.0\n",
      "ECYSTYSEMI     0.0\n",
      "ECYSTYROW      0.0\n",
      "ECYSTYAPT      0.0\n",
      "ECYSTYAP5P     0.0\n",
      "ECYSTYAPU5     0.0\n",
      "ECYSTYDUPL     0.0\n",
      "ECYSTYOTHR     0.0\n",
      "ECYSTYOATT     0.0\n",
      "ECYSTYMOVE     0.0\n",
      "ECYCDOHHD      0.0\n",
      "ECYCDOCO       0.0\n",
      "ECYCDOOWCO     0.0\n",
      "ECYCDORECO     0.0\n",
      "ECYCDONC       0.0\n",
      "ECYCDOOWNC     0.0\n",
      "ECYCDORENC     0.0\n",
      "ECYCDOBAND     0.0\n",
      "ECYHRIHHD      0.0\n",
      "ECYHRI_020     0.0\n",
      "ECYHRI2040     0.0\n",
      "ECYHRI4060     0.0\n",
      "ECYHRI6080     0.0\n",
      "ECYHRIX100     0.0\n",
      "ECYHRI100P     0.0\n",
      "ECYHRIX125     0.0\n",
      "ECYHRIX150     0.0\n",
      "ECYHRIX200     0.0\n",
      "ECYHRI200P     0.0\n",
      "ECYHRIX300     0.0\n",
      "ECYHRI300P     0.0\n",
      "ECYHRIAVG      0.0\n",
      "ECYHRIMED      0.0\n",
      "ECYHRIAGG      0.0\n",
      "ECYHNIHHD      0.0\n",
      "ECYHNI_020     0.0\n",
      "ECYHNI2040     0.0\n",
      "ECYHNI4060     0.0\n",
      "ECYHNI6080     0.0\n",
      "ECYHNIX100     0.0\n",
      "ECYHNI100P     0.0\n",
      "ECYHNIX125     0.0\n",
      "ECYHNIX150     0.0\n",
      "ECYHNIX200     0.0\n",
      "ECYHNI200P     0.0\n",
      "ECYHNIX300     0.0\n",
      "ECYHNI300P     0.0\n",
      "ECYHNIAVG      0.0\n",
      "ECYHNIMED      0.0\n",
      "ECYHNIAGG      0.0\n",
      "ECYPNIHP15     0.0\n",
      "ECYPNININ      0.0\n",
      "ECYPNIWIN      0.0\n",
      "ECYPNIAVG      0.0\n",
      "ECYEDUHP15     0.0\n",
      "ECYEDUNCDD     0.0\n",
      "ECYEDUHSCE     0.0\n",
      "ECYEDUATCD     0.0\n",
      "ECYEDUCOLL     0.0\n",
      "ECYEDUUDBB     0.0\n",
      "ECYEDUUD       0.0\n",
      "ECYEDUUDBD     0.0\n",
      "ECYEDUUDBP     0.0\n",
      "ECYEDAHPWK     0.0\n",
      "ECYEDANCDD     0.0\n",
      "ECYEDAHSCE     0.0\n",
      "ECYEDAATCD     0.0\n",
      "ECYEDACOLL     0.0\n",
      "ECYEDAUDBB     0.0\n",
      "ECYEDAUD       0.0\n",
      "ECYEDAUDBD     0.0\n",
      "ECYEDAUDBP     0.0\n",
      "ECYACTHPL      0.0\n",
      "ECYACTINLF     0.0\n",
      "ECYACTEMP      0.0\n",
      "ECYACTUEMP     0.0\n",
      "ECYACTNOLF     0.0\n",
      "ECYACTPR       0.0\n",
      "ECYACTER       0.0\n",
      "ECYACTUR       0.0\n",
      "ECYCWHPL       0.0\n",
      "ECYCWT         0.0\n",
      "ECYCWEMP       0.0\n",
      "ECYCWPSEI      0.0\n",
      "ECYOCCHPL      0.0\n",
      "ECYOCCINLF     0.0\n",
      "ECYOCCNA       0.0\n",
      "ECYOCCALL      0.0\n",
      "ECYOCCMGMT     0.0\n",
      "ECYOCCBFAD     0.0\n",
      "ECYOCCNSCI     0.0\n",
      "ECYOCCHLTH     0.0\n",
      "ECYOCCSSER     0.0\n",
      "ECYOCCARTS     0.0\n",
      "ECYOCCSERV     0.0\n",
      "ECYOCCTRAD     0.0\n",
      "ECYOCCPRIM     0.0\n",
      "ECYOCCSCND     0.0\n",
      "ECYINDHPL      0.0\n",
      "ECYINDINLF     0.0\n",
      "ECYINDNA       0.0\n",
      "ECYINDALL      0.0\n",
      "ECYINDAGRI     0.0\n",
      "ECYINDMINE     0.0\n",
      "ECYINDUTIL     0.0\n",
      "ECYINDCSTR     0.0\n",
      "ECYINDMANU     0.0\n",
      "ECYINDWHOL     0.0\n",
      "ECYINDRETL     0.0\n",
      "ECYINDTRAN     0.0\n",
      "ECYINDINFO     0.0\n",
      "ECYINDFINA     0.0\n",
      "ECYINDREAL     0.0\n",
      "ECYINDPROF     0.0\n",
      "ECYINDMGMT     0.0\n",
      "ECYINDADMN     0.0\n",
      "ECYINDEDUC     0.0\n",
      "ECYINDHLTH     0.0\n",
      "ECYINDARTS     0.0\n",
      "ECYINDACCO     0.0\n",
      "ECYINDOSER     0.0\n",
      "ECYINDPUBL     0.0\n",
      "ECYPOWHPL      0.0\n",
      "ECYPOWINLF     0.0\n",
      "ECYPOWEMP      0.0\n",
      "ECYPOWHOME     0.0\n",
      "ECYPOWOSCA     0.0\n",
      "ECYPOWNFIX     0.0\n",
      "ECYPOWUSUL     0.0\n",
      "ECYTRAHPL      0.0\n",
      "ECYTRAALL      0.0\n",
      "ECYTRADRIV     0.0\n",
      "ECYTRAPSGR     0.0\n",
      "ECYTRAPUBL     0.0\n",
      "ECYTRAWALK     0.0\n",
      "ECYTRABIKE     0.0\n",
      "ECYTRAOTHE     0.0\n",
      "ECYRELHPOP     0.0\n",
      "ECYRELBUDD     0.0\n",
      "ECYRELCHR      0.0\n",
      "ECYRELANGL     0.0\n",
      "ECYRELCATH     0.0\n",
      "ECYRELUNIT     0.0\n",
      "ECYRELOCHR     0.0\n",
      "ECYRELHIND     0.0\n",
      "ECYRELJEWI     0.0\n",
      "ECYRELMUSL     0.0\n",
      "ECYRELSIKH     0.0\n",
      "ECYRELOREL     0.0\n",
      "ECYRELNREL     0.0\n",
      "ECYVISHPOP     0.0\n",
      "ECYVISVM       0.0\n",
      "ECYVISCHIN     0.0\n",
      "ECYVISSA       0.0\n",
      "ECYVISBLCK     0.0\n",
      "ECYVISFILI     0.0\n",
      "ECYVISLAM      0.0\n",
      "ECYVISSEA      0.0\n",
      "ECYVISARAB     0.0\n",
      "ECYVISWA       0.0\n",
      "ECYVISKOR      0.0\n",
      "ECYVISJAPA     0.0\n",
      "ECYVISOVM      0.0\n",
      "ECYVISMVM      0.0\n",
      "ECYVISNVM      0.0\n",
      "ECYAIDHPOP     0.0\n",
      "ECYAIDABO      0.0\n",
      "ECYAIDNABO     0.0\n",
      "ECYKNOHPOP     0.0\n",
      "ECYKNOENGL     0.0\n",
      "ECYKNOFREN     0.0\n",
      "ECYKNOENFR     0.0\n",
      "ECYKNONEF      0.0\n",
      "ECYMOTHPOP     0.0\n",
      "ECYMOTSING     0.0\n",
      "ECYMOTENGL     0.0\n",
      "ECYMOTFREN     0.0\n",
      "ECYMOTNOFF     0.0\n",
      "ECYMOTITAL     0.0\n",
      "ECYMOTGERM     0.0\n",
      "ECYMOTPANJ     0.0\n",
      "ECYMOTCANT     0.0\n",
      "ECYMOTSPAN     0.0\n",
      "ECYMOTARAB     0.0\n",
      "ECYMOTTAGA     0.0\n",
      "ECYMOTPORT     0.0\n",
      "ECYMOTPOLI     0.0\n",
      "ECYMOTMAND     0.0\n",
      "ECYMOTCHIN     0.0\n",
      "ECYMOTURDU     0.0\n",
      "ECYMOTVIET     0.0\n",
      "ECYMOTUKRA     0.0\n",
      "ECYMOTPERS     0.0\n",
      "ECYMOTRUSS     0.0\n",
      "ECYMOTDUTC     0.0\n",
      "ECYMOTKORE     0.0\n",
      "ECYMOTGREE     0.0\n",
      "ECYMOTTAMI     0.0\n",
      "ECYMOTGUJA     0.0\n",
      "ECYMOTROMA     0.0\n",
      "ECYMOTHIND     0.0\n",
      "ECYMOTHUNG     0.0\n",
      "ECYMOTCROA     0.0\n",
      "ECYMOTCREO     0.0\n",
      "ECYMOTSERB     0.0\n",
      "ECYMOTBENG     0.0\n",
      "ECYMOTJAPA     0.0\n",
      "ECYMOTTURK     0.0\n",
      "ECYMOTCZEC     0.0\n",
      "ECYMOTSOMA     0.0\n",
      "ECYMOTABOR     0.0\n",
      "ECYMOTOTHR     0.0\n",
      "ECYMOTMULT     0.0\n",
      "ECYMOTENFR     0.0\n",
      "ECYMOTENON     0.0\n",
      "ECYMOTFNON     0.0\n",
      "ECYMOTEFNO     0.0\n",
      "ECYMOTMNON     0.0\n",
      "ECYHOMHPOP     0.0\n",
      "ECYHOMSING     0.0\n",
      "ECYHOMENGL     0.0\n",
      "ECYHOMFREN     0.0\n",
      "ECYHOMNOFF     0.0\n",
      "ECYHOMITAL     0.0\n",
      "ECYHOMGERM     0.0\n",
      "ECYHOMPANJ     0.0\n",
      "ECYHOMCANT     0.0\n",
      "ECYHOMSPAN     0.0\n",
      "ECYHOMARAB     0.0\n",
      "ECYHOMTAGA     0.0\n",
      "ECYHOMPORT     0.0\n",
      "ECYHOMPOLI     0.0\n",
      "ECYHOMMAND     0.0\n",
      "ECYHOMCHIN     0.0\n",
      "ECYHOMURDU     0.0\n",
      "ECYHOMVIET     0.0\n",
      "ECYHOMUKRA     0.0\n",
      "ECYHOMPERS     0.0\n",
      "ECYHOMRUSS     0.0\n",
      "ECYHOMDUTC     0.0\n",
      "ECYHOMKORE     0.0\n",
      "ECYHOMGREE     0.0\n",
      "ECYHOMTAMI     0.0\n",
      "ECYHOMGUJA     0.0\n",
      "ECYHOMROMA     0.0\n",
      "ECYHOMHIND     0.0\n",
      "ECYHOMHUNG     0.0\n",
      "ECYHOMCROA     0.0\n",
      "ECYHOMCREO     0.0\n",
      "ECYHOMSERB     0.0\n",
      "ECYHOMBENG     0.0\n",
      "ECYHOMJAPA     0.0\n",
      "ECYHOMTURK     0.0\n",
      "ECYHOMCZEC     0.0\n",
      "ECYHOMSOMA     0.0\n",
      "ECYHOMABOR     0.0\n",
      "ECYHOMOTHR     0.0\n",
      "ECYHOMMULT     0.0\n",
      "ECYHOMENFR     0.0\n",
      "ECYHOMENON     0.0\n",
      "ECYHOMFNON     0.0\n",
      "ECYHOMEFNO     0.0\n",
      "ECYHOMMNON     0.0\n",
      "ECYTIMHPOP     0.0\n",
      "ECYTIMNI       0.0\n",
      "ECYTIMNIIN     0.0\n",
      "ECYTIMNIOS     0.0\n",
      "ECYTIMIMGT     0.0\n",
      "ECYTIMAM       0.0\n",
      "ECYTIMNAM      0.0\n",
      "ECYTIMUSA      0.0\n",
      "ECYTIMONAM     0.0\n",
      "ECYTIMCAM      0.0\n",
      "ECYTIMELSA     0.0\n",
      "ECYTIMMEXI     0.0\n",
      "ECYTIMOCAM     0.0\n",
      "ECYTIMCB       0.0\n",
      "ECYTIMCUBA     0.0\n",
      "ECYTIMHAIT     0.0\n",
      "ECYTIMJAMA     0.0\n",
      "ECYTIMTRIN     0.0\n",
      "ECYTIMOCB      0.0\n",
      "ECYTIMSAM      0.0\n",
      "ECYTIMBRAZ     0.0\n",
      "ECYTIMCHIL     0.0\n",
      "ECYTIMCOLO     0.0\n",
      "ECYTIMGUYA     0.0\n",
      "ECYTIMPERU     0.0\n",
      "ECYTIMVENE     0.0\n",
      "ECYTIMOSAM     0.0\n",
      "ECYTIMEU       0.0\n",
      "ECYTIMWEU      0.0\n",
      "ECYTIMFRAN     0.0\n",
      "ECYTIMGERM     0.0\n",
      "ECYTIMNETH     0.0\n",
      "ECYTIMOWEU     0.0\n",
      "ECYTIMEEU      0.0\n",
      "ECYTIMCZEC     0.0\n",
      "ECYTIMHUNG     0.0\n",
      "ECYTIMMOLD     0.0\n",
      "ECYTIMPOLA     0.0\n",
      "ECYTIMROMA     0.0\n",
      "ECYTIMRUSS     0.0\n",
      "ECYTIMUKRA     0.0\n",
      "ECYTIMOEEU     0.0\n",
      "ECYTIMNEU      0.0\n",
      "ECYTIMUK       0.0\n",
      "ECYTIMIREL     0.0\n",
      "ECYTIMONEU     0.0\n",
      "ECYTIMSEU      0.0\n",
      "ECYTIMGREE     0.0\n",
      "ECYTIMITAL     0.0\n",
      "ECYTIMPORT     0.0\n",
      "ECYTIMBOSN     0.0\n",
      "ECYTIMCROA     0.0\n",
      "ECYTIMSERB     0.0\n",
      "ECYTIMOSEU     0.0\n",
      "ECYTIMAF       0.0\n",
      "ECYTIMWAF      0.0\n",
      "ECYTIMCOTE     0.0\n",
      "ECYTIMGHAN     0.0\n",
      "ECYTIMNIGE     0.0\n",
      "ECYTIMOWAF     0.0\n",
      "ECYTIMEAF      0.0\n",
      "ECYTIMERIT     0.0\n",
      "ECYTIMETHI     0.0\n",
      "ECYTIMKENY     0.0\n",
      "ECYTIMSOMA     0.0\n",
      "ECYTIMTANZ     0.0\n",
      "ECYTIMOEAF     0.0\n",
      "ECYTIMCAF      0.0\n",
      "ECYTIMCAME     0.0\n",
      "ECYTIMCONG     0.0\n",
      "ECYTIMCAFO     0.0\n",
      "ECYTIMNAF      0.0\n",
      "ECYTIMALGE     0.0\n",
      "ECYTIMEGYP     0.0\n",
      "ECYTIMMORO     0.0\n",
      "ECYTIMTUNI     0.0\n",
      "ECYTIMONAF     0.0\n",
      "ECYTIMSAF      0.0\n",
      "ECYTIMSAFR     0.0\n",
      "ECYTIMOSAF     0.0\n",
      "ECYTIMA        0.0\n",
      "ECYTIMWCA      0.0\n",
      "ECYTIMAFGH     0.0\n",
      "ECYTIMIRAN     0.0\n",
      "ECYTIMIRAQ     0.0\n",
      "ECYTIMISRA     0.0\n",
      "ECYTIMLEBA     0.0\n",
      "ECYTIMSAUD     0.0\n",
      "ECYTIMSYRI     0.0\n",
      "ECYTIMTURK     0.0\n",
      "ECYTIMUAE      0.0\n",
      "ECYTIMOWCA     0.0\n",
      "ECYTIMEA       0.0\n",
      "ECYTIMCHIN     0.0\n",
      "ECYTIMHONG     0.0\n",
      "ECYTIMJAPA     0.0\n",
      "ECYTIMSKOR     0.0\n",
      "ECYTIMTAIW     0.0\n",
      "ECYTIMOEA      0.0\n",
      "ECYTIMSEA      0.0\n",
      "ECYTIMCAMB     0.0\n",
      "ECYTIMMALA     0.0\n",
      "ECYTIMPHIL     0.0\n",
      "ECYTIMVIET     0.0\n",
      "ECYTIMOSEA     0.0\n",
      "ECYTIMSA       0.0\n",
      "ECYTIMBANG     0.0\n",
      "ECYTIMINDI     0.0\n",
      "ECYTIMNEPA     0.0\n",
      "ECYTIMPAKI     0.0\n",
      "ECYTIMSRI      0.0\n",
      "ECYTIMOSA      0.0\n",
      "ECYTIMOCE      0.0\n",
      "ECYTIMAUSS     0.0\n",
      "ECYTIMFIJI     0.0\n",
      "ECYTIMOOCE     0.0\n",
      "ECYTIMNPER     0.0\n",
      "ECYRIMHPOP     0.0\n",
      "ECYRIMRIM      0.0\n",
      "ECYRIMAM       0.0\n",
      "ECYRIMNAM      0.0\n",
      "ECYRIMCAM      0.0\n",
      "ECYRIMMEXI     0.0\n",
      "ECYRIMCAO      0.0\n",
      "ECYRIMCB       0.0\n",
      "ECYRIMCUBA     0.0\n",
      "ECYRIMHAIT     0.0\n",
      "ECYRIMJAMA     0.0\n",
      "ECYRIMCBO      0.0\n",
      "ECYRIMSAM      0.0\n",
      "ECYRIMBRAZ     0.0\n",
      "ECYRIMCOLO     0.0\n",
      "ECYRIMVENE     0.0\n",
      "ECYRIMSAO      0.0\n",
      "ECYRIMEU       0.0\n",
      "ECYRIMWEU      0.0\n",
      "ECYRIMFRAN     0.0\n",
      "ECYRIMGERM     0.0\n",
      "ECYRIMWEO      0.0\n",
      "ECYRIMEEU      0.0\n",
      "ECYRIMMOLD     0.0\n",
      "ECYRIMPOLA     0.0\n",
      "ECYRIMROMA     0.0\n",
      "ECYRIMRUSS     0.0\n",
      "ECYRIMUKRA     0.0\n",
      "ECYRIMEEO      0.0\n",
      "ECYRIMNEU      0.0\n",
      "ECYRIMUK       0.0\n",
      "ECYRIMNEO      0.0\n",
      "ECYRIMSEU      0.0\n",
      "ECYRIMAF       0.0\n",
      "ECYRIMWAF      0.0\n",
      "ECYRIMCOTE     0.0\n",
      "ECYRIMNIGE     0.0\n",
      "ECYRIMWAFO     0.0\n",
      "ECYRIMEAF      0.0\n",
      "ECYRIMERIT     0.0\n",
      "ECYRIMETHI     0.0\n",
      "ECYRIMKENY     0.0\n",
      "ECYRIMSOMA     0.0\n",
      "ECYRIMEAFO     0.0\n",
      "ECYRIMCAF      0.0\n",
      "ECYRIMNAF      0.0\n",
      "ECYRIMALGE     0.0\n",
      "ECYRIMEGYP     0.0\n",
      "ECYRIMMORO     0.0\n",
      "ECYRIMTUNI     0.0\n",
      "ECYRIMNAFO     0.0\n",
      "ECYRIMSAF      0.0\n",
      "ECYRIMA        0.0\n",
      "ECYRIMWCM      0.0\n",
      "ECYRIMAFGH     0.0\n",
      "ECYRIMIRAN     0.0\n",
      "ECYRIMIRAQ     0.0\n",
      "ECYRIMISRA     0.0\n",
      "ECYRIMLEBA     0.0\n",
      "ECYRIMSAUD     0.0\n",
      "ECYRIMSYRI     0.0\n",
      "ECYRIMTURK     0.0\n",
      "ECYRIMUAE      0.0\n",
      "ECYRIMWCMO     0.0\n",
      "ECYRIMEA       0.0\n",
      "ECYRIMCHIN     0.0\n",
      "ECYRIMHONG     0.0\n",
      "ECYRIMJAPA     0.0\n",
      "ECYRIMSKOR     0.0\n",
      "ECYRIMEAO      0.0\n",
      "ECYRIMSEA      0.0\n",
      "ECYRIMPHIL     0.0\n",
      "ECYRIMVIET     0.0\n",
      "ECYRIMSEAO     0.0\n",
      "ECYRIMSAS      0.0\n",
      "ECYRIMBANG     0.0\n",
      "ECYRIMINDI     0.0\n",
      "ECYRIMNEPA     0.0\n",
      "ECYRIMPAKI     0.0\n",
      "ECYRIMSRI      0.0\n",
      "ECYRIMSASO     0.0\n",
      "ECYRIMOCE      0.0\n",
      "ECYRIMAUSS     0.0\n",
      "ECYRIMOCEO     0.0\n",
      "ECYPIMHPOP     0.0\n",
      "ECYPIMNI       0.0\n",
      "ECYPIMIM       0.0\n",
      "ECYPIMP01      0.0\n",
      "ECYPIM0110     0.0\n",
      "ECYPIM1115     0.0\n",
      "ECYPIM1621     0.0\n",
      "ECYPIM22CY     0.0\n",
      "ECYPIMNPER     0.0\n",
      "ECYAIMHPOP     0.0\n",
      "ECYAIMNI       0.0\n",
      "ECYAIMIM       0.0\n",
      "ECYAIM_0_5     0.0\n",
      "ECYAIM_514     0.0\n",
      "ECYAIM1524     0.0\n",
      "ECYAIM2544     0.0\n",
      "ECYAIM45P      0.0\n",
      "ECYAIMNPER     0.0\n",
      "ECYGENHPOP     0.0\n",
      "ECYGEN1GEN     0.0\n",
      "ECYGEN2GEN     0.0\n",
      "ECYGEN3GEN     0.0\n",
      "ECYTCAHPOP     0.0\n",
      "ECYTCACIT      0.0\n",
      "ECYTCA_U18     0.0\n",
      "ECYTCA_18P     0.0\n",
      "ECYNCANCIT     0.0\n",
      "ECYNCA_U18     0.0\n",
      "ECYNCA_18P     0.0\n",
      "GEO_right      0.0\n",
      "HSBASHHD       0.0\n",
      "HSHNIAGG       0.0\n",
      "HSAGDISPIN     0.0\n",
      "HSAGDISCIN     0.0\n",
      "HSTT001        0.0\n",
      "HSTE001        0.0\n",
      "HSTX001        0.0\n",
      "HSTC001        0.0\n",
      "HSSH001S       0.0\n",
      "HSFD001S       0.0\n",
      "HSHO001S       0.0\n",
      "HSHC001S       0.0\n",
      "HSHF001S       0.0\n",
      "HSTR001S       0.0\n",
      "HSRE001S       0.0\n",
      "HSPC001S       0.0\n",
      "HSCL001S       0.0\n",
      "HSED002S       0.0\n",
      "HSRO001S       0.0\n",
      "HSTA001S       0.0\n",
      "HSGC001S       0.0\n",
      "HSME001S       0.0\n",
      "HSMG001S       0.0\n",
      "HSTE001ZBS     0.0\n",
      "HSWH002S       0.0\n",
      "HSWH028S       0.0\n",
      "HSWH040S       0.0\n",
      "HSWH041S       0.0\n",
      "HSWH042S       0.0\n",
      "HSSH001        0.0\n",
      "HSSH002        0.0\n",
      "HSSH003        0.0\n",
      "HSSH004        0.0\n",
      "HSSH053        0.0\n",
      "HSSH054        0.0\n",
      "HSSH005        0.0\n",
      "HSSH006        0.0\n",
      "HSSH007        0.0\n",
      "HSSH010        0.0\n",
      "HSSH011        0.0\n",
      "HSSH014        0.0\n",
      "HSSH013        0.0\n",
      "HSSH015        0.0\n",
      "HSSH016        0.0\n",
      "HSSH017        0.0\n",
      "HSSH018        0.0\n",
      "HSSH019        0.0\n",
      "HSSH021        0.0\n",
      "HSSH020        0.0\n",
      "HSSH022        0.0\n",
      "HSSH012        0.0\n",
      "HSRM002A       0.0\n",
      "HSRM002B       0.0\n",
      "HSRM003A       0.0\n",
      "HSRM003B       0.0\n",
      "HSRM004        0.0\n",
      "HSRM005        0.0\n",
      "HSRM006        0.0\n",
      "HSRM007        0.0\n",
      "HSRM008M       0.0\n",
      "HSRM009A       0.0\n",
      "HSRM009B       0.0\n",
      "HSRM010        0.0\n",
      "HSRM011        0.0\n",
      "HSRM012        0.0\n",
      "HSRM013        0.0\n",
      "HSRM015M       0.0\n",
      "HSRM016        0.0\n",
      "HSSH012B       0.0\n",
      "HSOI020        0.0\n",
      "HSOI020Z       0.0\n",
      "HSSH030        0.0\n",
      "HSSH031        0.0\n",
      "HSSH031A       0.0\n",
      "HSSH031B       0.0\n",
      "HSSH032        0.0\n",
      "HSSH032A       0.0\n",
      "HSSH032B       0.0\n",
      "HSSH033        0.0\n",
      "HSSH033A       0.0\n",
      "HSSH033B       0.0\n",
      "HSSH034        0.0\n",
      "HSSH035        0.0\n",
      "HSSH035A       0.0\n",
      "HSSH035B       0.0\n",
      "HSSH036        0.0\n",
      "HSSH036A       0.0\n",
      "HSSH036B       0.0\n",
      "HSSH037        0.0\n",
      "HSSH037A       0.0\n",
      "HSSH037B       0.0\n",
      "HSSH040        0.0\n",
      "HSSH041        0.0\n",
      "HSSH042        0.0\n",
      "HSSH043        0.0\n",
      "HSSH044        0.0\n",
      "HSSH045        0.0\n",
      "HSSH046        0.0\n",
      "HSSH046C       0.0\n",
      "HSSH046M       0.0\n",
      "HSSH047        0.0\n",
      "HSSH047A       0.0\n",
      "HSSH047C       0.0\n",
      "HSSH047M       0.0\n",
      "HSSH050        0.0\n",
      "HSSH051        0.0\n",
      "HSSH052        0.0\n",
      "HSFD001        0.0\n",
      "HSFD003        0.0\n",
      "HSFD990        0.0\n",
      "HSFD991        0.0\n",
      "HSFD992        0.0\n",
      "HSFD993        0.0\n",
      "HSFD994        0.0\n",
      "HSFD995        0.0\n",
      "HSHO001        0.0\n",
      "HSHO002        0.0\n",
      "HSHO003        0.0\n",
      "HSHO004        0.0\n",
      "HSHO005        0.0\n",
      "HSHO006        0.0\n",
      "HSHO010        0.0\n",
      "HSHO011        0.0\n",
      "HSHO012        0.0\n",
      "HSHO013        0.0\n",
      "HSHO014        0.0\n",
      "HSHO015        0.0\n",
      "HSHO016        0.0\n",
      "HSHO017        0.0\n",
      "HSHO018        0.0\n",
      "HSHO019        0.0\n",
      "HSHO020        0.0\n",
      "HSHO021        0.0\n",
      "HSHO022        0.0\n",
      "HSCC001        0.0\n",
      "HSCC002        0.0\n",
      "HSCC003        0.0\n",
      "HSCC013        0.0\n",
      "HSCC011        0.0\n",
      "HSCC012        0.0\n",
      "HSCC014        0.0\n",
      "HSCS001        0.0\n",
      "HSCS003        0.0\n",
      "HSCS004        0.0\n",
      "HSCS005        0.0\n",
      "HSCS011        0.0\n",
      "HSCS012        0.0\n",
      "HSCS013        0.0\n",
      "HSCS007        0.0\n",
      "HSCS008        0.0\n",
      "HSCS010        0.0\n",
      "HSHC001        0.0\n",
      "HSHC002        0.0\n",
      "HSHC003        0.0\n",
      "HSHC004        0.0\n",
      "HSHC004A       0.0\n",
      "HSHC004B       0.0\n",
      "HSHC005        0.0\n",
      "HSHC006        0.0\n",
      "HSHC006A       0.0\n",
      "HSHC006B       0.0\n",
      "HSHC007        0.0\n",
      "HSHC008        0.0\n",
      "HSHC009        0.0\n",
      "HSHC010        0.0\n",
      "HSHC012        0.0\n",
      "HSHC014        0.0\n",
      "HSHC027        0.0\n",
      "HSHC015        0.0\n",
      "HSHC022        0.0\n",
      "HSHC023        0.0\n",
      "HSHC024        0.0\n",
      "HSHC025        0.0\n",
      "HSHF001        0.0\n",
      "HSHF002        0.0\n",
      "HSHF003        0.0\n",
      "HSHF004        0.0\n",
      "HSHF005        0.0\n",
      "HSHF005A       0.0\n",
      "HSHF005B       0.0\n",
      "HSHF006        0.0\n",
      "HSHF008        0.0\n",
      "HSHE001        0.0\n",
      "HSHE002        0.0\n",
      "HSHE003        0.0\n",
      "HSHE004        0.0\n",
      "HSHE005        0.0\n",
      "HSHE006        0.0\n",
      "HSHE007        0.0\n",
      "HSHE009        0.0\n",
      "HSHE008        0.0\n",
      "HSHE010        0.0\n",
      "HSHE011        0.0\n",
      "HSHE011A       0.0\n",
      "HSHE011B       0.0\n",
      "HSHE031        0.0\n",
      "HSHE012        0.0\n",
      "HSHE012M       0.0\n",
      "HSHE032        0.0\n",
      "HSHE013        0.0\n",
      "HSHE015        0.0\n",
      "HSHE016        0.0\n",
      "HSHE020        0.0\n",
      "HSHE021        0.0\n",
      "HSHE023        0.0\n",
      "HSTR001        0.0\n",
      "HSTR002        0.0\n",
      "HSTR003        0.0\n",
      "HSTR004        0.0\n",
      "HSTR005        0.0\n",
      "HSTR006        0.0\n",
      "HSTR007        0.0\n",
      "HSTR008        0.0\n",
      "HSTR009        0.0\n",
      "HSTR058        0.0\n",
      "HSTR010        0.0\n",
      "HSTR011        0.0\n",
      "HSTR012        0.0\n",
      "HSTR014M       0.0\n",
      "HSTR015        0.0\n",
      "HSTR020        0.0\n",
      "HSTR030        0.0\n",
      "HSTR031        0.0\n",
      "HSTR032        0.0\n",
      "HSTR033        0.0\n",
      "HSTR034        0.0\n",
      "HSTR035        0.0\n",
      "HSTR036        0.0\n",
      "HSTR037        0.0\n",
      "HSTR038        0.0\n",
      "HSTR039        0.0\n",
      "HSTR040        0.0\n",
      "HSTR041        0.0\n",
      "HSTR050        0.0\n",
      "HSTR051        0.0\n",
      "HSTR052        0.0\n",
      "HSTR053        0.0\n",
      "HSTR054        0.0\n",
      "HSTR055        0.0\n",
      "HSTR056        0.0\n",
      "HSTR056A       0.0\n",
      "HSTR056B       0.0\n",
      "HSTR057        0.0\n"
     ]
    }
   ],
   "source": [
    "# Display entire row\n",
    "def display_row(df, row_index):\n",
    "    df = df.to_pandas()\n",
    "    with pd.option_context(\n",
    "        'display.max_columns', None,\n",
    "        'display.max_colwidth', None,\n",
    "        'display.width', None,\n",
    "        'display.expand_frame_repr', False\n",
    "    ):\n",
    "        row = df.iloc[row_index]\n",
    "        print(row.to_string())\n",
    "    return row\n",
    "\n",
    "row = display_row(merged_df_clust, 461)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Handle Nulls</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>That being said, we will need to remove these rows from our dataset. We will do this by removing any rows that contain only zeroes and nulls.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Null Count: {'ECYPMAMED': {'null_count': 8985, 'less than 1%': True}, 'ECYPFAMED': {'null_count': 44378, 'less than 1%': True}, 'ECYHTAMED': {'null_count': 5250, 'less than 1%': True}, 'ECYHMAMED': {'null_count': 14239, 'less than 1%': True}, 'ECYHFAMED': {'null_count': 50441, 'less than 1%': True}, 'ECYMTNMED': {'null_count': 5250, 'less than 1%': True}}\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with only nulls or zeros\n",
    "def remove_rows_with_nulls_or_zeros(df):\n",
    "    df = df.to_pandas()\n",
    "    # This mask is True for rows where all **non-null** values are 0\n",
    "    mask = df.apply(lambda row: (row.dropna() == 0).all(), axis=1)\n",
    "    df = df[~mask].reset_index(drop=True)\n",
    "    return pl.from_pandas(df)\n",
    "\n",
    "merged_df_clust = remove_rows_with_nulls_or_zeros(merged_df_clust)\n",
    "# Check for any remaining nulls\n",
    "merged_df_nulls = count_na_strings(merged_df_clust)\n",
    "print(f\"Data Null Count: {merged_df_nulls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>That definitely helped. We still have some nulls values but not as many. For the rest, we can substitute them with the median of the column. This is a common practice in data science and will help us keep our dataset clean.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling nulls in 'ECYPMAMED' with median = 40.0\n",
      "Filling nulls in 'ECYPFAMED' with median = 42.5\n",
      "Filling nulls in 'ECYHTAMED' with median = 41.1\n",
      "Filling nulls in 'ECYHMAMED' with median = 40.0\n",
      "Filling nulls in 'ECYHFAMED' with median = 42.5\n",
      "Filling nulls in 'ECYMTNMED' with median = 55.0\n",
      "Data Null Count: {}\n"
     ]
    }
   ],
   "source": [
    "def substitute_nulls_with_median(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    # Convert to Pandas\n",
    "    df_pd = df.to_pandas()\n",
    "\n",
    "    for col in df_pd.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df_pd[col]):\n",
    "            if df_pd[col].isnull().sum() > 0:\n",
    "                median = df_pd[col].median()\n",
    "                print(f\"Filling nulls in '{col}' with median = {median}\")\n",
    "                df_pd[col] = df_pd[col].fillna(median)\n",
    "\n",
    "    # Back to Polars\n",
    "    return pl.from_pandas(df_pd)\n",
    "\n",
    "\n",
    "merged_df_clust = substitute_nulls_with_median(merged_df_clust)\n",
    "\n",
    "merged_df_nulls = count_na_strings(merged_df_clust)\n",
    "print(f\"Data Null Count: {merged_df_nulls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Negative Values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Negative Values Count: {'HSTT001': {'negative_count': 28}, 'HSTE001ZBS': {'negative_count': 163557}, 'HSWH040S': {'negative_count': 255858}, 'HSWH041S': {'negative_count': 15436}, 'HSWH042S': {'negative_count': 19205}}\n"
     ]
    }
   ],
   "source": [
    "# Get total negative values for each column\n",
    "def count_negative_values(df):\n",
    "    return {\n",
    "        col: {\n",
    "            \"negative_count\": df[col].filter(df[col] < 0).len(),\n",
    "        }\n",
    "        for col in df.columns\n",
    "        if df.schema[col] in [pl.Int8, pl.Int16, pl.Int32, pl.Int64,\n",
    "                              pl.UInt8, pl.UInt16, pl.UInt32, pl.UInt64,\n",
    "                              pl.Float32, pl.Float64]\n",
    "        and df[col].filter(df[col] < 0).len() > 0\n",
    "    }\n",
    "\n",
    "# Get total negative values for each dataframe\n",
    "merged_df_negatives = count_negative_values(merged_df_clust)\n",
    "print(f\"Data Negative Values Count: {merged_df_negatives}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can see that there are negative values in the dataset:<p>\n",
    "<ul>\n",
    "<li>HSTT001 - Total expenditure,Household Expenditures (Category Summary),Dollars</li>\n",
    "<li>HSTE001ZBS - Total non-current consumption,Household Expenditures (Category Summary),Dollars</li>\n",
    "<li>HSWH040S,Net purchase price of owned residences,Household Expenditures (Category Summary),Dollars</li>\n",
    "<li>HSWH041S - Net purchase price of owned secondary residences,Household Expenditures (Category Summary),Dollars</li>\n",
    "<li>HSWH042S - Net purchase price of other owned properties,Household Expenditures (Category Summary),Dollars</li>\n",
    "</ul>\n",
    "<p>We can easily tell that the first two varaibles cannot be negative, since they desribe expenditures, and because they capture sums of outflows. The next 3 are tricky, because these variables reflect the net purchase price of owned residences, secondary residences, and other properties, they can indeed be negative if the proceeds from selling those properties exceed any purchase or improvement costs, thereby indicating a net inflow rather than an outflow.</p>\n",
    "<p>Therefore, we will remove the negatives in the first two variables, and keep the last three.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 28 rows with negative values in 'HSTT001'\n",
      "Removing 163557 rows with negative values in 'HSTE001ZBS'\n",
      "Data Negative Values Count: {'HSWH040S': {'negative_count': 92301}, 'HSWH041S': {'negative_count': 11752}, 'HSWH042S': {'negative_count': 11436}}\n"
     ]
    }
   ],
   "source": [
    "def remove_negatives(df, cols):\n",
    "    updated_df = df.clone()\n",
    "\n",
    "    for col in cols:\n",
    "        if col in df.columns:\n",
    "            neg_count = df.select((pl.col(col) < 0).sum()).item()\n",
    "\n",
    "            if neg_count > 0:\n",
    "                print(f\"Removing {neg_count} rows with negative values in '{col}'\")\n",
    "                updated_df = updated_df.filter(pl.col(col) >= 0)\n",
    "    return updated_df\n",
    "\n",
    "# Replace negative values with median\n",
    "merged_df_clust = remove_negatives(merged_df_clust, [\"HSTT001\", \"HSTE001ZBS\"])\n",
    "merged_df_negatives = count_negative_values(merged_df_clust)\n",
    "print(f\"Data Negative Values Count: {merged_df_negatives}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>General Clean Up</h3>\n",
    "<p>Here, we will be cleaning up any data that is redundant, such as rows with straight zeros, columns where the mean and std are both zero, implying that the column is constant, and any other data that is not useful.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 977)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>ECYBASPOP</th><th>ECYBASHHD</th><th>ECYBASHPOP</th><th>ECYBAS12P</th><th>ECYBAS15P</th><th>ECYBAS18P</th><th>ECYBAS19P</th><th>ECYBAS12HP</th><th>ECYBAS15HP</th><th>ECYBAS18HP</th><th>ECYBAS19HP</th><th>ECYBASTNGH</th><th>ECYBASADUH</th><th>ECYBASCF</th><th>ECYBASCFH</th><th>ECYBASKID</th><th>ECYBASLF</th><th>ECYPTAPOP</th><th>ECYPTA_0_4</th><th>ECYPTA_5_9</th><th>ECYPTA1014</th><th>ECYPTA1519</th><th>ECYPTA2024</th><th>ECYPTA2529</th><th>ECYPTA3034</th><th>ECYPTA3539</th><th>ECYPTA4044</th><th>ECYPTA4549</th><th>ECYPTA5054</th><th>ECYPTA5559</th><th>ECYPTA6064</th><th>ECYPTA6569</th><th>ECYPTA7074</th><th>ECYPTA7579</th><th>ECYPTA8084</th><th>ECYPTA85P</th><th>&hellip;</th><th>HSTR002</th><th>HSTR003</th><th>HSTR004</th><th>HSTR005</th><th>HSTR006</th><th>HSTR007</th><th>HSTR008</th><th>HSTR009</th><th>HSTR058</th><th>HSTR010</th><th>HSTR011</th><th>HSTR012</th><th>HSTR014M</th><th>HSTR015</th><th>HSTR020</th><th>HSTR030</th><th>HSTR031</th><th>HSTR032</th><th>HSTR033</th><th>HSTR034</th><th>HSTR035</th><th>HSTR036</th><th>HSTR037</th><th>HSTR038</th><th>HSTR039</th><th>HSTR040</th><th>HSTR041</th><th>HSTR050</th><th>HSTR051</th><th>HSTR052</th><th>HSTR053</th><th>HSTR054</th><th>HSTR055</th><th>HSTR056</th><th>HSTR056A</th><th>HSTR056B</th><th>HSTR057</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>&hellip;</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td><td>617954.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>51.742539</td><td>19.113623</td><td>50.761765</td><td>45.523842</td><td>43.591542</td><td>41.493731</td><td>40.914034</td><td>44.411497</td><td>42.63953</td><td>40.801189</td><td>40.195998</td><td>3.610308</td><td>26.68881</td><td>14.600158</td><td>13.762445</td><td>14.793632</td><td>27.339048</td><td>51.742539</td><td>2.443447</td><td>2.76979</td><td>2.937759</td><td>3.120187</td><td>3.44101</td><td>3.331793</td><td>3.480364</td><td>3.469626</td><td>3.454681</td><td>3.225303</td><td>3.166287</td><td>3.253745</td><td>3.550556</td><td>3.198329</td><td>2.562717</td><td>1.971472</td><td>1.218314</td><td>1.147158</td><td>&hellip;</td><td>276678.622614</td><td>139116.196812</td><td>134677.287547</td><td>16514.774281</td><td>10317.966871</td><td>107844.546395</td><td>217.799439</td><td>96.584268</td><td>121.215171</td><td>4221.109826</td><td>3924.151975</td><td>2240.60284</td><td>1683.549135</td><td>296.957851</td><td>1660.004524</td><td>135902.421278</td><td>3630.013422</td><td>11532.141467</td><td>14945.636495</td><td>20806.848445</td><td>121.115998</td><td>75356.65323</td><td>3054.225988</td><td>5007.741979</td><td>1448.044255</td><td>400.951644</td><td>1047.092611</td><td>35619.761351</td><td>4926.223543</td><td>2001.259018</td><td>975.685664</td><td>24980.478818</td><td>62.087184</td><td>1463.635381</td><td>963.768584</td><td>499.866798</td><td>1210.391742</td></tr><tr><td>&quot;std&quot;</td><td>201.02073</td><td>78.565243</td><td>197.415206</td><td>175.291238</td><td>167.493893</td><td>159.831028</td><td>157.855657</td><td>171.090556</td><td>164.107125</td><td>157.266205</td><td>155.101426</td><td>14.38619</td><td>99.801807</td><td>58.0313</td><td>55.38349</td><td>56.243707</td><td>102.35361</td><td>201.02073</td><td>10.871433</td><td>11.949518</td><td>12.34982</td><td>11.861756</td><td>11.967161</td><td>11.532242</td><td>12.630785</td><td>12.651026</td><td>12.663297</td><td>12.075512</td><td>12.198871</td><td>13.538138</td><td>15.969922</td><td>14.844441</td><td>12.098858</td><td>9.398165</td><td>5.864603</td><td>6.579977</td><td>&hellip;</td><td>1.1509e6</td><td>587008.076358</td><td>571977.189194</td><td>67242.183906</td><td>53810.858962</td><td>461165.730483</td><td>916.752953</td><td>414.218696</td><td>572.326949</td><td>15841.008562</td><td>14813.378462</td><td>8962.962229</td><td>6573.844642</td><td>1620.191388</td><td>6331.672324</td><td>566941.063716</td><td>16458.230917</td><td>45497.47891</td><td>70336.954211</td><td>83302.306728</td><td>722.273954</td><td>332787.352566</td><td>15573.064625</td><td>16070.674114</td><td>6498.48452</td><td>2426.192168</td><td>4326.980427</td><td>104708.078136</td><td>14730.04644</td><td>6580.764</td><td>5527.129774</td><td>77277.157921</td><td>256.044653</td><td>7577.650378</td><td>5857.255524</td><td>2325.258834</td><td>4655.495262</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>11.0</td><td>4.0</td><td>11.0</td><td>10.0</td><td>10.0</td><td>9.0</td><td>9.0</td><td>10.0</td><td>10.0</td><td>9.0</td><td>9.0</td><td>1.0</td><td>6.0</td><td>3.0</td><td>3.0</td><td>2.0</td><td>6.0</td><td>11.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>54399.105284</td><td>26045.005628</td><td>25198.56899</td><td>2875.068541</td><td>1572.207962</td><td>19700.280925</td><td>32.537719</td><td>15.029717</td><td>12.142886</td><td>612.958203</td><td>550.931064</td><td>292.982242</td><td>199.904684</td><td>15.927257</td><td>198.892739</td><td>27300.497755</td><td>500.893976</td><td>2016.381144</td><td>2633.224615</td><td>4082.289407</td><td>14.699409</td><td>14760.505952</td><td>353.973472</td><td>701.360896</td><td>237.823646</td><td>58.077148</td><td>153.210445</td><td>4675.564291</td><td>309.234609</td><td>271.666564</td><td>63.216573</td><td>3074.966879</td><td>9.433972</td><td>148.915672</td><td>67.589936</td><td>43.018501</td><td>147.92814</td></tr><tr><td>&quot;50%&quot;</td><td>25.0</td><td>10.0</td><td>25.0</td><td>23.0</td><td>22.0</td><td>21.0</td><td>21.0</td><td>22.0</td><td>21.0</td><td>21.0</td><td>20.0</td><td>2.0</td><td>13.0</td><td>7.0</td><td>7.0</td><td>7.0</td><td>13.0</td><td>25.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>&hellip;</td><td>127982.075489</td><td>62037.577617</td><td>59969.303022</td><td>7285.241124</td><td>4044.050831</td><td>47156.362602</td><td>85.303691</td><td>38.412757</td><td>35.773429</td><td>1645.437153</td><td>1503.221656</td><td>828.430004</td><td>573.702778</td><td>76.241946</td><td>610.057453</td><td>63851.244177</td><td>1236.962463</td><td>5281.661341</td><td>6430.90315</td><td>9892.603649</td><td>41.213428</td><td>34131.077451</td><td>992.890494</td><td>2153.239807</td><td>602.448174</td><td>143.002094</td><td>421.853329</td><td>14029.488574</td><td>1411.975876</td><td>809.803419</td><td>196.967912</td><td>9452.298833</td><td>26.479533</td><td>436.172692</td><td>217.711999</td><td>148.195472</td><td>433.58402</td></tr><tr><td>&quot;75%&quot;</td><td>52.0</td><td>19.0</td><td>51.0</td><td>45.0</td><td>44.0</td><td>42.0</td><td>41.0</td><td>45.0</td><td>43.0</td><td>41.0</td><td>41.0</td><td>3.0</td><td>27.0</td><td>15.0</td><td>14.0</td><td>15.0</td><td>28.0</td><td>52.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>4.0</td><td>3.0</td><td>4.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>4.0</td><td>3.0</td><td>3.0</td><td>2.0</td><td>1.0</td><td>1.0</td><td>&hellip;</td><td>272131.296444</td><td>136785.133946</td><td>132046.624916</td><td>16847.570199</td><td>9730.829249</td><td>104154.622254</td><td>209.123096</td><td>91.585517</td><td>99.72216</td><td>4222.446341</td><td>3904.186797</td><td>2175.422201</td><td>1566.173746</td><td>277.3198</td><td>1660.066357</td><td>133238.903778</td><td>3074.769555</td><td>11731.028508</td><td>14305.448633</td><td>21011.60135</td><td>106.273221</td><td>71523.260924</td><td>2612.057851</td><td>5480.538419</td><td>1427.518992</td><td>360.286265</td><td>1045.135362</td><td>37673.795885</td><td>5026.950591</td><td>2034.811861</td><td>584.856295</td><td>25926.474767</td><td>61.990184</td><td>1140.510726</td><td>642.117442</td><td>454.757107</td><td>1112.243396</td></tr><tr><td>&quot;max&quot;</td><td>23507.0</td><td>7751.0</td><td>23378.0</td><td>20141.0</td><td>19020.0</td><td>17849.0</td><td>17487.0</td><td>19950.0</td><td>18891.0</td><td>17781.0</td><td>17436.0</td><td>2169.0</td><td>11623.0</td><td>6837.0</td><td>6487.0</td><td>8218.0</td><td>13551.0</td><td>23507.0</td><td>1241.0</td><td>1530.0</td><td>1791.0</td><td>1871.0</td><td>1954.0</td><td>1200.0</td><td>1478.0</td><td>1437.0</td><td>1811.0</td><td>1723.0</td><td>1617.0</td><td>1545.0</td><td>1393.0</td><td>1293.0</td><td>1193.0</td><td>1139.0</td><td>700.0</td><td>663.0</td><td>&hellip;</td><td>1.2796e8</td><td>7.0898e7</td><td>6.8704e7</td><td>8.7079e6</td><td>1.0164e7</td><td>5.2694e7</td><td>98537.879231</td><td>43886.395799</td><td>62217.543041</td><td>2.1477e6</td><td>2.1443e6</td><td>1.3459e6</td><td>895523.577009</td><td>272687.971232</td><td>1.1006e6</td><td>5.8696e7</td><td>1.9230e6</td><td>5.4522e6</td><td>9.1193e6</td><td>8.5339e6</td><td>128411.834084</td><td>3.7197e7</td><td>2.9165e6</td><td>1.8141e6</td><td>1.0225e6</td><td>406708.260287</td><td>615838.990473</td><td>1.2478e7</td><td>2.3201e6</td><td>1.0707e6</td><td>653408.354038</td><td>9.9506e6</td><td>29234.466882</td><td>1.4912e6</td><td>1.2078e6</td><td>397905.142758</td><td>733300.179849</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 977)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ statistic ┆ ECYBASPOP ┆ ECYBASHHD ┆ ECYBASHPO ┆ … ┆ HSTR056   ┆ HSTR056A  ┆ HSTR056B  ┆ HSTR057  │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ P         ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ str       ┆ f64       ┆ f64       ┆ ---       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
       "│           ┆           ┆           ┆ f64       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ count     ┆ 617954.0  ┆ 617954.0  ┆ 617954.0  ┆ … ┆ 617954.0  ┆ 617954.0  ┆ 617954.0  ┆ 617954.0 │\n",
       "│ null_coun ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0      │\n",
       "│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ mean      ┆ 51.742539 ┆ 19.113623 ┆ 50.761765 ┆ … ┆ 1463.6353 ┆ 963.76858 ┆ 499.86679 ┆ 1210.391 │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 81        ┆ 4         ┆ 8         ┆ 742      │\n",
       "│ std       ┆ 201.02073 ┆ 78.565243 ┆ 197.41520 ┆ … ┆ 7577.6503 ┆ 5857.2555 ┆ 2325.2588 ┆ 4655.495 │\n",
       "│           ┆           ┆           ┆ 6         ┆   ┆ 78        ┆ 24        ┆ 34        ┆ 262      │\n",
       "│ min       ┆ 1.0       ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0      │\n",
       "│ 25%       ┆ 11.0      ┆ 4.0       ┆ 11.0      ┆ … ┆ 148.91567 ┆ 67.589936 ┆ 43.018501 ┆ 147.9281 │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 2         ┆           ┆           ┆ 4        │\n",
       "│ 50%       ┆ 25.0      ┆ 10.0      ┆ 25.0      ┆ … ┆ 436.17269 ┆ 217.71199 ┆ 148.19547 ┆ 433.5840 │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 2         ┆ 9         ┆ 2         ┆ 2        │\n",
       "│ 75%       ┆ 52.0      ┆ 19.0      ┆ 51.0      ┆ … ┆ 1140.5107 ┆ 642.11744 ┆ 454.75710 ┆ 1112.243 │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 26        ┆ 2         ┆ 7         ┆ 396      │\n",
       "│ max       ┆ 23507.0   ┆ 7751.0    ┆ 23378.0   ┆ … ┆ 1.4912e6  ┆ 1.2078e6  ┆ 397905.14 ┆ 733300.1 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 2758      ┆ 79849    │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_up(merged_df_clust):\n",
    "    # Drop any rows that contain straight 0's in all columns\n",
    "    columns_to_check = [col for col in merged_df_clust.columns if merged_df_clust.schema[col] in (pl.Int64, pl.Float64)]\n",
    "    merged_df_clust = merged_df_clust.filter(\n",
    "        ~pl.all_horizontal([pl.col(col) == 0 for col in columns_to_check])\n",
    "    )\n",
    "\n",
    "    # Drop any columns where the mean and std are both 0\n",
    "    columns_to_drop = [\n",
    "        col for col in merged_df_clust.columns\n",
    "        if merged_df_clust.schema[col] in (pl.Int64, pl.Float64)\n",
    "        and merged_df_clust[col].mean() == 0\n",
    "        and merged_df_clust[col].std() == 0\n",
    "    ]\n",
    "    merged_df_clust = merged_df_clust.drop(columns_to_drop)\n",
    "    return merged_df_clust\n",
    "\n",
    "merged_df_clust = clean_up(merged_df_clust)\n",
    "\n",
    "merged_df_clust.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Correlated Variables</h3>\n",
    "<p>Now, we will be looking for correlated variables. We will be using the correlation matrix to find the correlation between the variables.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Start by removing anything with the word retirement, pension, insurance, premium\n",
    "except for target column calculation variable</p>\n",
    "<p>We do this because we are trying to predict the target variable, which is the Total personal insurance premiums and retirement/pension contributions. We want to remove any variables that are correlated with the target variable, so that we can get a better prediction.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_related_target_columns(merged_df_clust):\n",
    "    # Drop columns that are related to the target variable\n",
    "    columns_to_drop = [\n",
    "        \"HSEP001\", \"HSSH006\", \"HSSH014\", \"HSSH019\", \"HSSH044\", \"HSEP002\",\n",
    "        \"HSEP003\", \"HSEP004\", \"HSEP005\", \"HSEP006\", \"HSEP007\", \"HSEP008\",\n",
    "        \"HSEP009\", \"HSHC022\", \"HSHC023\", \"HSHC024\", \"HSHC025\", \"HSTR025\",\n",
    "        \"HSRV011\"\n",
    "    ]\n",
    "    for col in columns_to_drop:\n",
    "        if col in merged_df_clust.columns:\n",
    "            merged_df_clust = merged_df_clust.drop(col)\n",
    "            \n",
    "    return merged_df_clust\n",
    "\n",
    "\n",
    "merged_df_clust = drop_related_target_columns(merged_df_clust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now, lets create a function to remove perfectly correlated variables. We will be using the correlation matrix to find the correlation between the variables.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df Highly Correlated Variables: shape: (132, 3)\n",
      "┌────────────┬────────────┬─────────────┐\n",
      "│ var_1      ┆ var_2      ┆ correlation │\n",
      "│ ---        ┆ ---        ┆ ---         │\n",
      "│ str        ┆ str        ┆ f64         │\n",
      "╞════════════╪════════════╪═════════════╡\n",
      "│ ECYBASPOP  ┆ ECYPTAPOP  ┆ 1.0         │\n",
      "│ ECYBASHPOP ┆ ECYHTAHPOP ┆ 1.0         │\n",
      "│ ECYBASHPOP ┆ ECYHSZTPER ┆ 1.0         │\n",
      "│ ECYBASHPOP ┆ ECYRELHPOP ┆ 1.0         │\n",
      "│ ECYBASHPOP ┆ ECYVISHPOP ┆ 1.0         │\n",
      "│ …          ┆ …          ┆ …           │\n",
      "│ ECYAIMHPOP ┆ ECYGENHPOP ┆ 1.0         │\n",
      "│ ECYAIMHPOP ┆ ECYTCAHPOP ┆ 1.0         │\n",
      "│ ECYGENHPOP ┆ ECYTCAHPOP ┆ 1.0         │\n",
      "│ HSFD001S   ┆ HSFD001    ┆ 1.0         │\n",
      "│ HSHF001S   ┆ HSHF001    ┆ 1.0         │\n",
      "└────────────┴────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "def summarize_perfectly_correlated_vars(df):\n",
    "    numeric_df = df.select(pl.selectors.numeric())\n",
    "    corr_matrix = numeric_df.corr()\n",
    "    columns = numeric_df.columns\n",
    "\n",
    "    correlated_pairs = {\n",
    "        \"var_1\": [],\n",
    "        \"var_2\": [],\n",
    "        \"correlation\": []\n",
    "    }\n",
    "\n",
    "    for i in range(len(columns)):\n",
    "        for j in range(i + 1, len(columns)):\n",
    "            corr_value = corr_matrix.select(columns[j]).row(i)[0]\n",
    "            if corr_value == 1.0 or corr_value == -1.0:\n",
    "                correlated_pairs[\"var_1\"].append(columns[i])\n",
    "                correlated_pairs[\"var_2\"].append(columns[j])\n",
    "                correlated_pairs[\"correlation\"].append(corr_value)\n",
    "\n",
    "    return pl.DataFrame(correlated_pairs).sort(\"correlation\", descending=True)\n",
    "\n",
    "\n",
    "# Get highly correlated variables\n",
    "df_correlated = summarize_perfectly_correlated_vars(merged_df_clust)\n",
    "print(\"Df Highly Correlated Variables:\", df_correlated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can see that certain variables are highly correlated with other variables, this is because we have a large number of aggregate variables that are derived from the same underlying data. To fix this, we will drop variables with a correlation count of over 1, since these can be determined as having redundancy.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 32 highly correlated columns:\n",
      "['ECYACTINLF', 'ECYAIDHPOP', 'ECYAIMHPOP', 'ECYAIMIM', 'ECYAIMNI', 'ECYCHA_0_4', 'ECYCHA_5_9', 'ECYCWHPL', 'ECYCWT', 'ECYEDAHPWK', 'ECYEDUHP15', 'ECYGENHPOP', 'ECYHNIAGG', 'ECYHOMHPOP', 'ECYHSZTPER', 'ECYHTAHPOP', 'ECYINDINLF', 'ECYKNOHPOP', 'ECYMOTHPOP', 'ECYOCCINLF', 'ECYPIMHPOP', 'ECYPOWINLF', 'ECYPTAPOP', 'ECYRELHPOP', 'ECYRIMHPOP', 'ECYSTYHHD', 'ECYTCAHPOP', 'ECYTIMHPOP', 'ECYVISHPOP', 'HSFD001', 'HSHF001', 'HSHNIAGG']\n"
     ]
    }
   ],
   "source": [
    "def remove_perfectly_correlated_columns(df: pl.DataFrame) -> tuple[pl.DataFrame, list[str]]:\n",
    "    numeric_df = df.select(pl.selectors.numeric())\n",
    "    corr_matrix = numeric_df.corr()\n",
    "    columns = numeric_df.columns\n",
    "    to_drop = set()\n",
    "    already_seen = set()\n",
    "\n",
    "    for i in range(len(columns)):\n",
    "        col_i = columns[i]\n",
    "        if col_i in to_drop:\n",
    "            continue\n",
    "        for j in range(i + 1, len(columns)):\n",
    "            col_j = columns[j]\n",
    "            if col_j in to_drop:\n",
    "                continue\n",
    "            corr_val = corr_matrix.select(col_j).row(i)[0]\n",
    "            if abs(corr_val) == 1.0 and col_j not in already_seen:\n",
    "                to_drop.add(col_j)\n",
    "        already_seen.add(col_i)\n",
    "\n",
    "    cleaned_df = df.drop(to_drop)\n",
    "    return cleaned_df, sorted(to_drop)\n",
    "\n",
    "\n",
    "merged_df_clust, dropped_columns = remove_perfectly_correlated_columns(merged_df_clust)\n",
    "print(f\"Dropped {len(dropped_columns)} highly correlated columns:\")\n",
    "print(dropped_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Outliers</h3>\n",
    "<p>One major issue with this data is how skewed it is. The data is heavily skewed to the right, with a very long tail. For example, we are getting values of over 20,000, tailing all the way down to 100, but then the mean of that column will be around 40.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_distribution(df, column, xlim=None, numbins=300):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df[column], bins=numbins, kde=True)\n",
    "    plt.title(f\"Distribution of {column}\")\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    if xlim:\n",
    "        plt.xlim(xlim)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "plot_distribution(merged_df_clust, \"ECYBASPOP\", xlim=(0, 1000), numbins=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You can clearly see how skewed the data is. The mean is around 40, but the median is around 20. This is a clear indication that the data is skewed to the right. We can also see that the data has a long tail that goes past 1000 (it actually goes to 20,000).</p>\n",
    "<p>To fix this, we will first use a power transform to make the data more normal.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_power_transformer(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    # Convert to Pandas\n",
    "    df_pd = df.to_pandas()\n",
    "\n",
    "    # Identify numeric columns\n",
    "    numeric_cols = df_pd.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "    # Apply PowerTransformer to each numeric column\n",
    "    transformer = PowerTransformer(standardize=False)\n",
    "    df_pd[numeric_cols] = transformer.fit_transform(df_pd[numeric_cols])\n",
    "\n",
    "    # Convert back to Polars\n",
    "    return pl.from_pandas(df_pd)\n",
    "\n",
    "cleaned_df = apply_power_transformer(merged_df_clust)\n",
    "\n",
    "plot_distribution(cleaned_df, \"ECYBASPOP\", xlim=(0, 20), numbins=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Final Statistics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Width: {cleaned_df.width}\")\n",
    "print(f\"Height: {cleaned_df.height}\")\n",
    "\n",
    "cleaned_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can see our data is left with 936 columns and just over 600,000 rows.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Clustering</h2>\n",
    "<p>We will be using the KMeans clustering algorithm to cluster the data. We will be using the elbow method, in contrast with the silhouette method to find the optimal number of clusters.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Scaling</h3>\n",
    "<p>Scaling will be completed using the RobustScaler, which is a scaler that is robust to outliers. This will help us to scale the data without being affected by the outliers.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scaler \n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Convert to Pandas DataFrame for scaling\n",
    "cleaned_df = cleaned_df.to_pandas()\n",
    "\n",
    "# Fit the scaler to the data\n",
    "scaler.fit(cleaned_df)\n",
    "\n",
    "# Transform the data\n",
    "scaled_data = scaler.transform(cleaned_df)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=cleaned_df.columns)\n",
    "\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create a sample of the data</h3>\n",
    "<p>We will create a sample of the data, so that we can run our clustering models faster.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 20% of the data\n",
    "sampled_df = scaled_df.sample(frac=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_stats = scaled_df.mean()[:5]\n",
    "sample_stats = sampled_df.mean()[:5]\n",
    "\n",
    "print(\"Full Data Means:\\n\", full_stats)\n",
    "print(\"\\nSample Data Means:\\n\", sample_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>K-Means Clustering</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create a K-Means clustering of the data, identifying the optimal number of\n",
    "clusters using both the silhouette and the elbow method.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Start by using the elbow method to identify the optimal number of clusters.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KClusterer\n",
    "KClusterer = KMeans(n_clusters=3,\n",
    "                    verbose=0,\n",
    "                    random_state=2025)\n",
    "# Use KElbowVisualizer to find optimal number of clusters\n",
    "visualizer = KElbowVisualizer(KClusterer, # Cluster model with any parameters you need\n",
    "                              k=(2,16),   # Number of clusters to test (2 to 12 in this case)\n",
    "                              locate_elbow=True, # Locate the elbow? Default is true.\n",
    "                              timings=False # Plot the timings to train?\n",
    "                             )\n",
    "\n",
    "visualizer.fit(sampled_df)       # Fit the data to the visualizer\n",
    "visualizer.show()        # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can see the optimal number of clusters is 5, since the knee of the curve is at 5. This is a weak elbow, so we can confirm by using the silouette method.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette Analysis\n",
    "def plot_silhouette(data, n_clusters):\n",
    "    # Initialize the clusterer\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=2025)\n",
    "    cluster_labels = clusterer.fit_predict(data)\n",
    "\n",
    "    silhouette_avg = silhouette_score(data, cluster_labels)\n",
    "    sample_silhouette_values = silhouette_samples(data, cluster_labels)\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        plt.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          alpha=0.7)\n",
    "        plt.text(-0.1, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "        y_lower = y_upper + 10\n",
    "    plt.title(f\"Silhouette plot for {n_clusters} clusters\")\n",
    "    plt.xlabel(\"Silhouette coefficient values\")\n",
    "    plt.ylabel(\"Cluster label\")\n",
    "    plt.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "    plt.show()\n",
    "\n",
    "# Run silhouette analysis with optimal clusters\n",
    "plot_silhouette(sampled_df, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>While the distortion elbow suggested five clusters, silhouette analysis showed that a three-cluster solution provided significantly better cohesion and separation, with an average silhouette score of ~0.23. Even though 0.23 is weak, it is still considered acceptable for high-dimensional and real-world demographic data, where perfect separation is rare. The clusters are well-balanced in size, showed no signs of singled groups. Therefore, k=3 is most likely the ideal number of clusters.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dimensionality Reduction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Apply PCA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine k-clusterer with optimal number of clusters\n",
    "KClusterer = KMeans(n_clusters=3,\n",
    "                    verbose=0,\n",
    "                    random_state=2025)\n",
    "\n",
    "# Fit the model\n",
    "cluster_labels = KClusterer.fit_predict(sampled_df)\n",
    "\n",
    "# Apply PCA to scaled data\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(sampled_df)\n",
    "\n",
    "# Wrap into DataFrame for visualization/analysis\n",
    "pca_df = pd.DataFrame(X_pca, columns=[\"PC1\", \"PC2\", \"PC3\"])\n",
    "pca_df[\"Cluster\"] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=pca_df, x=\"PC1\", y=\"PC2\", hue=\"Cluster\", palette=\"tab10\", s=10)\n",
    "plt.title(\"PCA Projection (PC1 vs PC2) Colored by Cluster\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.legend(title=\"Cluster\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top contributing features for each component\n",
    "components = pd.DataFrame(\n",
    "    pca.components_, \n",
    "    columns=scaled_df.columns, \n",
    "    index=[\"PC1\", \"PC2\", \"PC3\"]\n",
    ")\n",
    "\n",
    "for pc in components.index:\n",
    "    print(f\"\\n{pc} top features:\")\n",
    "    print(components.loc[pc].abs().sort_values(ascending=False).head(5))\n",
    "\n",
    "# Average PCA component values by cluster\n",
    "avg_components_by_cluster = pca_df.groupby(\"Cluster\")[[\"PC1\", \"PC2\", \"PC3\"]].mean().reset_index()\n",
    "print(\"\\nAverage component values by cluster:\")\n",
    "print(avg_components_by_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>UMAP</h3>\n",
    "<p>Now we will apply UMAP to reduce the dimensionality of the data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP with commonly good starting values\n",
    "umap_model = umap.UMAP(n_neighbors=75,\n",
    "                    n_components=2,\n",
    "                    metric='cosine',\n",
    "                    n_epochs=None,\n",
    "                    min_dist=0.05,\n",
    "                    spread=1.0,\n",
    "                    low_memory=False,\n",
    "                    n_jobs=-1,\n",
    "                    verbose=True\n",
    "                   )\n",
    "\n",
    "umap_2d = umap_model.fit_transform(sampled_df)\n",
    "\n",
    "# Create DataFrame\n",
    "umap_df = pd.DataFrame(umap_2d, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "umap_df[\"Cluster\"] = cluster_labels\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=umap_df, x=\"UMAP1\", y=\"UMAP2\", hue=\"Cluster\", palette=\"tab10\", s=10)\n",
    "plt.title(\"UMAP Projection Colored by Cluster\")\n",
    "plt.xlabel(\"UMAP Dimension 1\")\n",
    "plt.ylabel(\"UMAP Dimension 2\")\n",
    "plt.legend(title=\"Cluster\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>UMAP appears to perform worse than PCA. The clusters are less distinct</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Part 2: Regression</h1>\n",
    "\n",
    "Now we will create models for a household’s proportion of income spent\n",
    "on total personal insurance premiums and retirement/pension contributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a regularized elastic net linear regression from your data.\n",
    "\n",
    "1. Create your target variable from the variables in the dataset. Do not use\n",
    "those components on the training database.\n",
    "2. Apply any data transformation / variable creation you deem necessary to\n",
    "obtain a good result.\n",
    "3. Discuss the grid that you chose to search for the parameters and the output\n",
    "that you obtained.\n",
    "4. For your test set, create a scatterplot of the original response and the\n",
    "predicted response. Report the MSE and R2 on the test set and calculate a\n",
    "bootstrapped confidence interval of the output.\n",
    "5. Interpret the coefficients of the top five most important variables in the\n",
    "regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Splitting into Train and Test</h3>\n",
    "<p>We will split the data into a training and test set. We will use 30% of the data for training and 70% for testing.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "train, test = train_test_split(merged_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Preprocessing</h3>\n",
    "<p>We will be using the same preprocessing steps as before, but considering the case that we now have train and test sets</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_processing_pipeline(train, test, target_column):\n",
    "     # Make sure Polars\n",
    "    if not isinstance(train, pl.DataFrame):\n",
    "        train = pl.from_pandas(train)\n",
    "    if not isinstance(test, pl.DataFrame):\n",
    "        test = pl.from_pandas(test)\n",
    "\n",
    "    # === Preprocess TRAIN ===\n",
    "    train = convert_na_to_nulls(train)\n",
    "    train = convert_strings_to_numbers(train)\n",
    "    train = remove_rows_with_nulls_or_zeros(train)\n",
    "    train = substitute_nulls_with_median(train)\n",
    "    train = remove_negatives(train, [\"HSTT001\", \"HSTE001ZBS\"])\n",
    "    train = clean_up(train)\n",
    "    train = drop_related_target_columns(train)\n",
    "\n",
    "    # Drop correlated columns on TRAIN only, then reuse\n",
    "    train, dropped_cols = remove_perfectly_correlated_columns(train)\n",
    "\n",
    "    # Apply power transformation\n",
    "    train = apply_power_transformer(train)\n",
    "\n",
    "    # === Preprocess TEST ===\n",
    "    test = convert_na_to_nulls(test)\n",
    "    test = convert_strings_to_numbers(test)\n",
    "    test = remove_rows_with_nulls_or_zeros(test)\n",
    "    test = substitute_nulls_with_median(test)\n",
    "    test = remove_negatives(test, [\"HSTT001\", \"HSTE001ZBS\"])\n",
    "    test = clean_up(test)\n",
    "    test = drop_related_target_columns(test)\n",
    "\n",
    "    # Drop the same correlated columns from test\n",
    "    test = test.drop([col for col in dropped_cols if col in test.columns])\n",
    "\n",
    "    # Apply power transformation\n",
    "    test = apply_power_transformer(test)\n",
    "\n",
    "    # === Separate target ===\n",
    "    y_train = train[target_column].to_pandas().reset_index(drop=True)\n",
    "    X_train = train.drop(target_column)\n",
    "    y_test = test[target_column].to_pandas().reset_index(drop=True)\n",
    "    X_test = test.drop(target_column)\n",
    "\n",
    "    # === Scale features ===\n",
    "    scaler = RobustScaler()\n",
    "    column_names = X_train.columns\n",
    "\n",
    "    X_train = X_train.to_pandas()\n",
    "    X_test = X_test.to_pandas()\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    X_train = pd.DataFrame(X_train_scaled, columns=column_names)\n",
    "    X_test = pd.DataFrame(X_test_scaled, columns=column_names)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling nulls in 'ECYPMAMED' with median = 40.0\n",
      "Filling nulls in 'ECYPFAMED' with median = 42.5\n",
      "Filling nulls in 'ECYHTAMED' with median = 41.1\n",
      "Filling nulls in 'ECYHMAMED' with median = 40.0\n",
      "Filling nulls in 'ECYHFAMED' with median = 42.5\n",
      "Filling nulls in 'ECYMTNMED' with median = 55.0\n",
      "Removing 22 rows with negative values in 'HSTT001'\n",
      "Removing 130876 rows with negative values in 'HSTE001ZBS'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling nulls in 'ECYPMAMED' with median = 40.0\n",
      "Filling nulls in 'ECYPFAMED' with median = 42.5\n",
      "Filling nulls in 'ECYHTAMED' with median = 41.1\n",
      "Filling nulls in 'ECYHMAMED' with median = 40.0\n",
      "Filling nulls in 'ECYHFAMED' with median = 42.5\n",
      "Filling nulls in 'ECYMTNMED' with median = 55.0\n",
      "Removing 6 rows with negative values in 'HSTT001'\n",
      "Removing 32681 rows with negative values in 'HSTE001ZBS'\n",
      "X_train shape: (494324, 930)\n",
      "X_test shape: (123630, 930)\n",
      "y_train shape: (494324,)\n",
      "y_test shape: (123630,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = full_processing_pipeline(train, test, \"HSEP001S\")\n",
    "\n",
    "\n",
    "# Check if the shapes of X_train and X_test are the same\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "# Check if the shapes of y_train and y_test are the same\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Sample 20% of the training data\n",
    "sample_indices = X_train.sample(frac=0.20, random_state=2025).index\n",
    "\n",
    "# Apply the same index to both X and y\n",
    "sampled_X_train = X_train.loc[sample_indices]\n",
    "sampled_y_train = y_train.loc[sample_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Elastic Net</h2>\n",
    "<h3>Grid Search</h3>\n",
    "<p>We will be using a grid search to find the optimal parameters for the elastic net model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.001\n",
      "Best l1_ratio: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Set up grid search for alpha and l1_ratio\n",
    "param_grid = {\n",
    "    'alphas': [0.001, 0.005, 0.01],\n",
    "    'l1_ratio': [0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "# Initialize the ElasticNetCV model\n",
    "elastic_net = ElasticNetCV(\n",
    "    alphas=param_grid['alphas'],\n",
    "    l1_ratio=param_grid['l1_ratio'],\n",
    "    cv=5,\n",
    "    max_iter=20000,\n",
    "    tol=1e-2,\n",
    "    n_jobs=-1,\n",
    "    random_state=2025\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "elastic_net.fit(sampled_X_train, sampled_y_train)\n",
    "\n",
    "print(f\"Best alpha: {elastic_net.alpha_}\")\n",
    "print(f\"Best l1_ratio: {elastic_net.l1_ratio_}\")\n",
    "\n",
    "final_model = ElasticNet(\n",
    "    alpha=elastic_net.alpha_,\n",
    "    l1_ratio=elastic_net.l1_ratio_,\n",
    "    max_iter=20000,\n",
    "    random_state=2025\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model Evaluation</h3>\n",
    "<p>We will be using the mean squared error and R2 score to evaluate the model. We will also be using a bootstrapped confidence interval to evaluate the model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the final model on the sampled training data\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Set MSE: {mse:.4f}\")\n",
    "print(f\"Test Set R²: {r2:.4f}\")\n",
    "\n",
    "# Plot: Actual vs Predicted\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.3)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Actual vs Predicted (Test Set)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Bootstrapped CI\n",
    "n_bootstraps = 1000\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "y_test_array = np.array(y_test)\n",
    "y_pred_array = np.array(y_pred)\n",
    "\n",
    "for _ in range(n_bootstraps):\n",
    "    indices = np.random.choice(len(y_test_array), len(y_test_array), replace=True)\n",
    "    mse_scores.append(mean_squared_error(y_test_array[indices], y_pred_array[indices]))\n",
    "    r2_scores.append(r2_score(y_test_array[indices], y_pred_array[indices]))\n",
    "\n",
    "mse_ci = np.percentile(mse_scores, [2.5, 97.5])\n",
    "r2_ci = np.percentile(r2_scores, [2.5, 97.5])\n",
    "\n",
    "print(f\"95% CI for MSE: [{mse_ci[0]:.4f}, {mse_ci[1]:.4f}]\")\n",
    "print(f\"95% CI for R²: [{r2_ci[0]:.4f}, {r2_ci[1]:.4f}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
